{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical analyses libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import natsort\n",
    "import scipy\n",
    "from scipy.signal import sosfiltfilt, butter, hilbert\n",
    "import scipy.signal as signal\n",
    "# libraries for interacting/setting directories for the data\n",
    "import os\n",
    "import mne\n",
    "from bids.layout import BIDSLayout\n",
    "from pathlib import Path\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# consulting the PyBIDS documentation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general functions:\n",
    "- using layout.get_tasks() to identify strings ; layout.to_df() ; layout.get_tasks() ; using dir(anyclass...) to get all applicable functions, besides the 'dunder' functions\n",
    "- help(layout) ; print(bids.__version__)  to get version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating directory structure for accessing and processing all .edf files; Github solution to empty solutions issue previously (https://github.com/bids-standard/pybids/issues/978)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:\\\\Users\\\\josep\\\\Music&Topology' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising the layout\n",
    "layout = BIDSLayout(data_path,validate=True)\n",
    "layout\n",
    "\n",
    "layout.get(return_type=\"id\", target=\"subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating subject-level directory paths w/ Github solution\n",
    "subject_dirs = [Path(data_path) / 'all-subjects' / f'sub-{subject}' for subject in layout.get_subjects()]\n",
    "subject_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 招 Pathlib documentation,\n",
    "Path('C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-01\\\\eeg\\\\sub-01_task-classicalMusic_eeg.edf').exists()\n",
    "\n",
    "#since my '.edf' files do indeed exist (lol), going forward with making dictionaries, epoching, all that good stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting from the root of dataset, search for all .edf files w/Pathlib, since pybids didn't work\n",
    "all_edf_files = list(Path(layout.root).rglob('*.edf'))\n",
    "\n",
    "# Print all findable .edf files, using Pathlib from above\n",
    "for file in all_edf_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique subject directories, or the parents of the EEG directories from all_edf_files\n",
    "all_subject_dirs_with_edf = list({file.parent.parent for file in all_edf_files})\n",
    "\n",
    "for dir in all_subject_dirs_with_edf:\n",
    "    print(dir.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-processing: filtering, selecting subjects, ICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- general outline: \n",
    "\n",
    "  1. select subjects from visual inspection of channels filtered for delta, theta and alpha bands, looking for subjects with the least inter-subject variability in EEG patterns.\n",
    "  2. from selected subjects, ICA loop from 1-30 hz for raw-->raw-with-ICA-weights data; continuous data & still not trial-segmented\n",
    "  3. re-filter the raw-with-ICA-weights data for each subject for delta, theta and alpha bands, 0.5-13 hz\n",
    "  4. filter as well for four bands, for ' α (1–7 Hz), β (8–13 Hz), θ (14–30 Hz), and γ bands (30–45 Hz)' for the DL model from 'EEG-Based Emotion Classification...'\n",
    "  3. extract & visualize the non-EEG channels' data\n",
    "  4. follow musical moment epoching procedure from pg. 7-8 from notebook\n",
    "\n",
    "  #keep for later, after the filtering and after the trial segmentations\n",
    "  #your actual epochs, for musical moments\n",
    "  \n",
    "  epochs_output_folder = \"C:\\\\Users\\\\josep\\\\Music&Topology\\\\Analysis\\\\epochs_data\"\n",
    "  if not os.path.exists(epochs_output_folder):\n",
    "    os.makedirs(epochs_output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = {\n",
    "    'ExpStart': 1,\n",
    "    'TTL': 10,\n",
    "    'TTL-relay': 47,\n",
    "    'Artifact:pulse': 265,\n",
    "    'Trial start': 768,\n",
    "    'ecg:Q-wave-onset, QRS-onset': 1283,\n",
    "    'ecg:S-wave-onset, S-wave-peak': 1285,\n",
    "    'unused': 34053,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#from participants.tsv\n",
    "\n",
    "#participant_id\tage\tsex\n",
    "#sub-01\t29\tF\n",
    "#sub-02\t21\tF\n",
    "#sub-03\t26\tM\n",
    "#sub-04\t25\tM\n",
    "#sub-05\t25\tM\n",
    "#sub-06\t26\tM\n",
    "#sub-07\t27\tF\n",
    "#sub-08\t26\tF\n",
    "#sub-09\t26\tF\n",
    "#sub-10\t27\tM\n",
    "#sub-11\t20\tF\n",
    "#sub-12\t23\tF\n",
    "#sub-13\t20\tM\n",
    "#sub-14\t22\tF\n",
    "#sub-15\t23\tM\n",
    "#sub-16\t23\tM\n",
    "#sub-17\t22\tF\n",
    "#sub-18\t21\tF\n",
    "#sub-19\t24\tM\n",
    "#sub-20\t27\tM\n",
    "#sub-21\t28\tM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# continuation from 10/24: visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize this; define 'preprocess_data' function\n",
    "\n",
    "# Define frequency bands\n",
    "delta_band = (1, 4)\n",
    "theta_band = (4, 7)\n",
    "alpha_band = (8, 13)\n",
    "\n",
    "# Define a combined filter band that spans delta, theta, and alpha frequencies\n",
    "combined_band = (delta_band[0], alpha_band[1])\n",
    "\n",
    "def preprocess_data(subject_id):\n",
    "    # Load the EEG data\n",
    "    file_name = f\"C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-{subject_id:02d}\\\\eeg\\\\sub-{subject_id:02d}_task-classicalMusic_eeg.edf\"\n",
    "    raw = mne.io.read_raw_edf(file_name, preload=True)\n",
    "    \n",
    "    # Bandpass filter the data for the combined frequency band (theta + alpha)\n",
    "    raw_combined = raw.copy().filter(l_freq=combined_band[0], h_freq=combined_band[1])\n",
    "    \n",
    "    return raw_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize this; define 'preprocess_data_and_plot' function\n",
    "# automating to have each plot for each selected channel saved as a PNG, saved in a folder for that respective subject, then upload to GPT-4 for a 'second take' noise analysis\n",
    "import os\n",
    "\n",
    "\n",
    "def preprocess_data_and_plot(subject_id):\n",
    "    # Define the channels of interest\n",
    "    channels_of_interest = ['Fp1', 'Fp2', 'F3', 'F4', 'F7', 'F8', 'P3', 'P4', 'P7', 'P8', 'T7', 'T8', 'Fz', 'Cz', 'Pz', 'Oz', 'FC1', 'FC2', 'CP1', 'CP2', 'FC5', 'FC6', 'CP5', 'CP6', 'TP9', 'TP10', 'POz']\n",
    "\n",
    "    # Define the path to the preprocessed data\n",
    "    # Load the preprocessed data\n",
    "    raw_combined = preprocess_data(subject_id)\n",
    "\n",
    "    # Define time range\n",
    "    start, stop = raw_combined.time_as_index([30, 2000])\n",
    "\n",
    "    # Directory where the plots will be saved\n",
    "    save_dir = f\"C:\\\\Users\\\\josep\\\\Music&Topology\\\\Analysis\\\\Analysis\\\\r[{subject_id}];)\"\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Loop through each channel and plot\n",
    "    for channel in channels_of_interest:\n",
    "        # Extracting data for the channel\n",
    "        combined_data, _ = raw_combined[channel, start:stop]\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(raw_combined.times[start:stop], combined_data.T)\n",
    "        plt.title(f'Theta and Alpha Filtered EEG Data for Channel {channel} (30s to 2000s)')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('EEG amplitude (uV)')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot to the specified directory with the channel name\n",
    "        plt.savefig(os.path.join(save_dir, f\"{channel}_filtered.png\"))\n",
    "        \n",
    "        plt.close()  # Close the current plot before moving to the next\n",
    "\n",
    "# usage for a single subject; change () number to subject_id\n",
    "preprocess_data_and_plot(21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# continuation since 10/27: steps 1-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1: selected subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of selected subjects from the above visual inspection step; 'sub_using' folder has the PNG's for these\n",
    "selected_subjects = ['02', '04', '05', '10', '17', '19', '21']\n",
    "\n",
    "# Filter out directories that match the 'sub-XX' format and are in the list of selected subjects\n",
    "selected_subject_dirs = [dir for dir in all_subject_dirs_with_edf if 'sub-' in dir.name and any(sub in dir.name for sub in selected_subjects)]\n",
    "\n",
    "# Print the directories of the selected subjects\n",
    "print(selected_subject_dirs)  \n",
    "\n",
    "for dir in selected_subject_dirs:\n",
    "    print(dir.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring the non-EEG channels w/in the '...channels.tsv' file of each subject, before conducting ICA and following analyses\n",
    "\n",
    "# Load the EEG data for one of the subjects (you can change this to any other subject's file)\n",
    "edf_file = Path(\"C:/Users/josep/Music&Topology/all-subjects/sub-16/eeg/sub-16_task-classicalMusic_eeg.edf\")\n",
    "raw = mne.io.read_raw_edf(edf_file, preload=True)\n",
    "\n",
    "# List of additional channels\n",
    "additional_channels = ['ECG', 'ft_valence', 'ft_arousal', 'ft_x', 'ft_y', 'ft_ghostvalence', \n",
    "                       'ft_ghostarousal', 'music', 'trialtype', 'sams_valence', 'sams_arousal', \n",
    "                       'sams_valencert', 'sams_arousalrt', 'nback_stimuli', 'nback_keypress']\n",
    "\n",
    "# Pick only the additional channels for visualization\n",
    "raw.pick_channels(additional_channels)\n",
    "\n",
    "# Plot the time courses of these channels\n",
    "raw.plot(start=0, duration=60)  # Displaying 60 seconds for illustration, adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation/Epoching the time series, based on trial type and piece of music\n",
    "# The value of the music channel indicates which piece of music (from the stimuli folder) was played to the participant in a given trial. To convert from the values stored in this channel to the music channel: 1) multiply the value by 20, 2) convert to a string, 3) the file name is then constructed from the resulting 3-element number. For example, if the number is 282 this indicates file 2-8_2.wav from the stimuli folder.\n",
    "\n",
    "# Extract data for the trialtype and music channels\n",
    "trialtype_data = raw.copy().pick_channels(['trialtype']).get_data()[0]\n",
    "music_data = raw.copy().pick_channels(['music']).get_data()[0]\n",
    "\n",
    "# Let's plot these channels to visualize the changes\n",
    "times = raw.times\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(times, trialtype_data)\n",
    "plt.title('trialtype')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(times, music_data)\n",
    "plt.title('music')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: ICA, filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop for filtering & ICA on the raw data-->raw-with-ICA-weights\n",
    "\n",
    "channels_of_interest = ['F3', 'F4', 'F7', 'F8', 'P3', 'P4', 'P7', 'P8', \n",
    "                        'T7', 'T8', 'Fz', 'Cz', 'Pz', 'Oz', 'FC1', 'FC2', 'CP1', 'CP2', \n",
    "                        'FC5', 'FC6', 'CP5', 'CP6', 'TP9', 'TP10', 'POz']\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "output_folder = \"C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\raw-with-ICA-weights\" \n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Create ICA properties plots output folder\n",
    "ica_plots_folder = \"C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\images\\\\ICAproperties\"\n",
    "if not os.path.exists(ica_plots_folder):\n",
    "    os.makedirs(ica_plots_folder)\n",
    "\n",
    "# Iterate over the selected subject directories\n",
    "for dir in selected_subject_dirs:\n",
    "    edf_files_in_dir = [f for f in dir.glob('eeg/*.edf') if 'classicalMusic' in f.name]\n",
    "    for edf_file in edf_files_in_dir:\n",
    "        # Load the EEG data\n",
    "        raw = mne.io.read_raw_edf(edf_file, preload=True)\n",
    "     \n",
    "        # Notch filter to remove 50 Hz line noise\n",
    "        raw.notch_filter([50], filter_length='auto', phase='zero')\n",
    "        \n",
    "        # Band-pass filter for delta, theta, and alpha bands\n",
    "        raw.filter(l_freq=1, h_freq=30)\n",
    "         \n",
    "        # Reference the EEG data to its average\n",
    "        raw.set_eeg_reference(ref_channels='average')\n",
    "    \n",
    "        # Explicitly drop non-EEG channels\n",
    "        non_eeg_channels = ['ECG', 'ft_valance', 'ft_arousal', 'ft_x', 'ft_y', 'ft_ghostvalence', \n",
    "                            'ft_ghostarousal', 'music', 'trialtype', 'sams_valence', 'sams_arousal', \n",
    "                            'sams_valencert', 'sams_arousalrt', 'nback_stimuli', 'nback_keypress']\n",
    "\n",
    "        raw.drop_channels(non_eeg_channels)\n",
    "\n",
    "        # Set the standard 10/20 montage\n",
    "        montage = mne.channels.make_standard_montage('standard_1020')\n",
    "        raw.set_montage(montage)\n",
    "\n",
    "        raw.pick_channels(channels_of_interest, ordered=False)\n",
    "        \n",
    "        # Use ICA to remove artifacts\n",
    "        ica = mne.preprocessing.ICA(n_components=25, random_state=97, max_iter=800)\n",
    "        ica.fit(raw)\n",
    "        \n",
    "        # Plot and save the ICA components' properties including the power spectrum for GPT-4 'second eye' inspection\n",
    "        for idx in range(25):\n",
    "            fig = ica.plot_properties(raw, picks=idx, show=False)\n",
    "            subject_id = dir.name.split('-')[-1]\n",
    "            fig_name = f\"ICA_sub{subject_id}-plot{idx+1}.png\"\n",
    "            fig[0].savefig(os.path.join(ica_plots_folder, fig_name))\n",
    "            plt.close(fig[0])  # close the figure to free up memory\n",
    "        \n",
    "        # Exclude selected components\n",
    "        ica.exclude = [int(i) for i in input(f\"Enter indices of components to exclude for {edf_file.name} (comma-separated): \").split(\",\")]\n",
    "\n",
    "        # Apply the ICA to the raw data\n",
    "        raw = ica.apply(raw)\n",
    "\n",
    "        # Save the preprocessed data with the specified filename\n",
    "        raw.save(os.path.join(output_folder, f\"{edf_file.stem}_raw-with-ICA-weights.fif\"), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process raw-with-ICA-weights data for DL model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process raw-with-ICA-weights data for analyses\n",
    "\n",
    "import mne\n",
    "import os\n",
    "\n",
    "# List of subjects' raw data with applied ICA weights\n",
    "subjects_files = [\n",
    "    \"C:/Users/josep/Music&Topology/all work ;)/Analysis1/raw-with-ICA-weights/raw-with-ICA-weights/sub-02_task-classicalMusic_eeg_raw-with-ICA-weights.fif\",\n",
    "    \"C:/Users/josep/Music&Topology/all work ;)/Analysis1/raw-with-ICA-weights/raw-with-ICA-weights/sub-04_task-classicalMusic_eeg_raw-with-ICA-weights.fif\",\n",
    "    \"C:/Users/josep/Music&Topology/all work ;)/Analysis1/raw-with-ICA-weights/raw-with-ICA-weights/sub-05_task-classicalMusic_eeg_raw-with-ICA-weights.fif\",\n",
    "    \"C:/Users/josep/Music&Topology/all work ;)/Analysis1/raw-with-ICA-weights/raw-with-ICA-weights/sub-10_task-classicalMusic_eeg_raw-with-ICA-weights.fif\",\n",
    "    \"C:/Users/josep/Music&Topology/all work ;)/Analysis1/raw-with-ICA-weights/raw-with-ICA-weights/sub-17_task-classicalMusic_eeg_raw-with-ICA-weights.fif\",\n",
    "    \"C:/Users/josep/Music&Topology/all work ;)/Analysis1/raw-with-ICA-weights/raw-with-ICA-weights/sub-19_task-classicalMusic_eeg_raw-with-ICA-weights.fif\",\n",
    "    \"C:/Users/josep/Music&Topology/all work ;)/Analysis1/raw-with-ICA-weights/raw-with-ICA-weights/sub-21_task-classicalMusic_eeg_raw-with-ICA-weights.fif\"\n",
    "]\n",
    "\n",
    "# Create output folder if it doesn't exist                                                                                                                                          \n",
    "output_folder = \"C:/Users/josep/Music&Topology/all work ;)/Analysis1/processed-for-analysis\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for subject_file in subjects_files:\n",
    "    # Load the raw data\n",
    "    raw = mne.io.read_raw_fif(subject_file, preload=True)\n",
    "    \n",
    "    # Notch filter to remove 50 Hz line noise\n",
    "    raw.notch_filter([50], filter_length='auto', phase='zero')\n",
    "    \n",
    "    # Band-pass filter for delta, theta, and alpha bands\n",
    "    raw.filter(l_freq=0.5, h_freq=13)\n",
    "     \n",
    "    # Reference the EEG data to its average\n",
    "    raw.set_eeg_reference(ref_channels='average')\n",
    "    \n",
    "   # Extract the filename without the path and extension\n",
    "    filename = os.path.basename(subject_file).split('.')[0]\n",
    "\n",
    "    # Construct the new filename with \"filtered-and-referenced.fif\" added\n",
    "    new_filename = f\"{filename}-filtered-and-referenced_analysis.fif\"\n",
    "\n",
    "    # Create the full output path in the output_folder\n",
    "    output_path = os.path.join(output_folder, new_filename)\n",
    "\n",
    "    # Save the modified data to the new location\n",
    "    raw.save(output_path)\n",
    "\n",
    "print(\"All files have been filtered, re-referenced, and saved in the processed-for-analysis folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization check\n",
    "\n",
    "'''\n",
    "import os\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_data_and_plot(subject_id):\n",
    "    # Define the path to the processed data for the subject\n",
    "    file_path = f\"C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\processed-for-analysis\\\\sub-{subject_id:02d}_task-classicalMusic_eeg_raw-with-ICA-weights-filtered-and-referenced_analysis.fif\"\n",
    "    \n",
    "    # Load the processed data\n",
    "    raw_processed = mne.io.read_raw_fif(file_path, preload=True)\n",
    "    \n",
    "    # Define the channels of interest\n",
    "    channels_of_interest = ['F3', 'F4', 'F7', 'F8', 'P3', 'P4', 'P7', 'P8', 'T7', 'T8', 'Fz', 'Cz', 'Pz', 'Oz', 'FC1', 'FC2', 'CP1', 'CP2', 'FC5', 'FC6', 'CP5', 'CP6', 'TP9', 'TP10', 'POz']\n",
    "\n",
    "    # Define time range\n",
    "    start, stop = raw_processed.time_as_index([10, 2000])\n",
    "\n",
    "    # Directory where the plots will be saved\n",
    "    save_dir = \"C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\images\\\\processing check\"\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Loop through each channel and plot\n",
    "    for channel in channels_of_interest:\n",
    "        # Extracting data for the channel\n",
    "        combined_data, _ = raw_processed[channel, start:stop]\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(raw_processed.times[start:stop], combined_data.T)\n",
    "        plt.title(f'Theta and Alpha Filtered EEG Data for Channel {channel} (30s to 2000s)')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('EEG amplitude (uV)')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot to the specified directory with the channel name\n",
    "        plt.savefig(os.path.join(save_dir, f\"sub-{subject_id:02d}_{channel}_filtered.png\"))\n",
    "                \n",
    "# usage for a single subject; change () number to subject_id\n",
    "preprocess_data_and_plot(2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3: non-EEG channels' visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop for visualization of non-EEG channels; clarification for next steps\n",
    "\n",
    "import os\n",
    "\n",
    "# Iterate over the selected subject directories\n",
    "for dir in selected_subject_dirs:\n",
    "    # Get only the classical music EDF files\n",
    "    classical_music_files = list(dir.glob('eeg/*task-classicalMusic_eeg.edf'))\n",
    "    \n",
    "    for edf_file in classical_music_files:\n",
    "        # Load the data\n",
    "        raw = mne.io.read_raw_edf(edf_file, preload=True)\n",
    "        \n",
    "        # Get the indices of the non-EEG channels\n",
    "        non_eeg_channels = ['ft_valance', 'ft_arousal', 'music', 'trialtype']\n",
    "        channel_indices = [raw.ch_names.index(ch) for ch in non_eeg_channels if ch in raw.ch_names]\n",
    "\n",
    "        # For each non-EEG channel, plot the data using plt\n",
    "        for ch_idx in channel_indices:\n",
    "            data, times = raw[ch_idx, :]\n",
    "    \n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.plot(times, data.T)\n",
    "            plt.title(f\"{raw.ch_names[ch_idx]} for {edf_file.stem}\")\n",
    "            plt.xlabel('Time (s)')\n",
    "            plt.ylabel('Value')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "'''\n",
    "music\tstimuli\tV\tgood\t\n",
    "The value of the music channel indicates which piece of music (from the stimuli folder) was played to the participant\n",
    "in a given trial. To convert from the values stored in this channel to the music channel: 1) multiply the value by 20, 2) \n",
    "convert to a string, 3) the file name is then constructed from the resulting 3-element number. For example, \n",
    "if the number is 282 this indicates file 2-8_2.wav from the stimuli folder.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: visualization of the trialsegs, setting up for epochs; first, for music-and-reporting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The raw data and their corresponding timestamps/event markers for the music-and-reporting trialsegs are as follows:\n",
    "\n",
    " raw file:\n",
    " 'C:\\Users\\josep\\Music&Topology\\all-subjects\\sub-02\\eeg\\sub-02_task-classicalMusic_eeg.edf'\n",
    "corresponding timestamps for epochs:\n",
    "17.092-175.484 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub02\\\\sub02_music-and-reporting_p3-epo.fif'\n",
    "175.484-308.868 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\sub02\\\\sub02_music-and-reporting_p6-or-p2-epo.fif'\n",
    "\n",
    "raw file:\n",
    "'C:\\Users\\josep\\Music&Topology\\all-subjects\\sub-04\\eeg\\sub-04_task-classicalMusic_eeg.edf'\n",
    "corresponding timestamps for epochs:\n",
    "175.555-337.511 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub04\\\\sub04_music-and-reporting_p5-undecided-epo.fif'\n",
    "337.511-472.401 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub04\\\\sub04_music-and-reporting_p6-or-p2-epo.fif'\n",
    "605.756-761.398 (s) for 'C:\\\\Users\\\\josep\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub04\\\\sub04_music-and-reporting_p3-epo.fif'\n",
    "1059.81-1225.402 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub04\\\\sub04_music-and-reporting_p5-undecided-epo.fif'\n",
    "\n",
    "raw file:\n",
    "'C:\\Users\\josep\\Music&Topology\\all-subjects\\sub-05\\eeg\\sub-05_task-classicalMusic_eeg.edf'\n",
    "corresponding timestamps for epochs:\n",
    "14.594-148.165 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub05\\\\sub05_music-and-reporting_p6-or-p2-epo.fif'\n",
    "282.772-448.714 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub05\\\\sub05_music-and-reporting_p5-undecided-epo.fif'\n",
    "908.811-1065.856 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub05\\\\sub05_music-and-reporting_p3-epo.fif'\n",
    "1224.351-1389.993 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub05\\\\sub05_music-and-reporting_p5-undecided-epo.fif'\n",
    "\n",
    "raw file:\n",
    "'C:\\Users\\josep\\Music&Topology\\all-subjects\\sub-10\\eeg\\sub-10_task-classicalMusic_eeg.edf'\n",
    "corresponding timestamps for epochs:\n",
    "14.906-149.429 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub10\\\\sub10_music-and-reporting_p6-or-p2-epo.fif'\n",
    "447.09-602.681 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub10\\\\sub10_music-and-reporting_p3-epo.fif'\n",
    "769.324-932.846 (s) for C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub10\\\\sub10_music-and-reporting_p5-undecided-epo.fif'\n",
    "1089.656-1254.697 (s) for C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub10\\\\sub10_music-and-reporting_p5-undecided-epo.fif'\n",
    "\n",
    "raw file:\n",
    "'C:\\Users\\josep\\Music&Topology\\all-subjects\\sub-17\\eeg\\sub-17_task-classicalMusic_eeg.edf'\n",
    "corresponding timestamps for epochs:\n",
    "14.109-172.254 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub17\\\\sub17_music-and-reporting_p3-epo.fif'\n",
    "172.254-339.316 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub17\\\\sub17_music-and-reporting_p5-undecided-epo.fif'\n",
    "628.262-791.817 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub17\\\\sub17_music-and-reporting_p5-undecided-epo.fif'\n",
    "791.817-925.556 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub17\\\\sub17_music-and-reporting_p6-or-p2-epo.fif'\n",
    "\n",
    "raw file:\n",
    "'C:\\Users\\josep\\Music&Topology\\all-subjects\\sub-19\\eeg\\sub-19_task-classicalMusic_eeg.edf'\n",
    "corresponding timestamps for epochs:\n",
    "179.071-344.363 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub19\\\\sub19_music-and-reporting_p5-undecided-epo.fif'\n",
    "502.826-637.032 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub19\\\\sub19_music-and-reporting_p6-or-p2-epo.fif'\n",
    "637.032-794.395 (s) for  'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub19\\\\sub19_music-and-reporting_p3-epo.fif'\n",
    "1124.542-1288.438 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub19\\\\sub19_music-and-reporting_p5-undecided-epo.fif'\n",
    "\n",
    "raw file:\n",
    "'C:\\Users\\josep\\Music&Topology\\all-subjects\\sub-21\\eeg\\sub-21_task-classicalMusic_eeg.edf'\n",
    "corresponding timestamps for epochs:\n",
    "180.259-345.484 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub21\\\\sub21_music-and-reporting_p5-undecided-epo.fif'\n",
    "502.01-636.067 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub21\\\\sub21_music-and-reporting_p6-or-p2-epo.fif''\n",
    "636.067-791.376 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub21\\\\sub21_music-and-reporting_p3-epo.fif'\n",
    "1121.608-1285.497 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub21\\\\sub21_music-and-reporting_p5-undecided-epo.fif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of music-and-reporting trialsegs files to visualize\n",
    "epoch_files = ['C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub02\\\\sub02_music-and-reporting_p3-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\sub02\\\\sub02_music-and-reporting_p6-or-p2-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub04\\\\sub04_music-and-reporting_p3-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub04\\\\sub04_music-and-reporting_p5-undecided-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub04\\\\sub04_music-and-reporting_p6-or-p2-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub05\\\\sub05_music-and-reporting_p3-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub05\\\\sub05_music-and-reporting_p5-undecided-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub05\\\\sub05_music-and-reporting_p6-or-p2-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub10\\\\sub10_music-and-reporting_p3-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub10\\\\sub10_music-and-reporting_p5-undecided-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub10\\\\sub10_music-and-reporting_p6-or-p2-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub17\\\\sub17_music-and-reporting_p3-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub17\\\\sub17_music-and-reporting_p5-undecided-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub17\\\\sub17_music-and-reporting_p6-or-p2-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub19\\\\sub19_music-and-reporting_p3-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub19\\\\sub19_music-and-reporting_p5-undecided-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub19\\\\sub19_music-and-reporting_p6-or-p2-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub21\\\\sub21_music-and-reporting_p3-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub21\\\\sub21_music-and-reporting_p5-undecided-epo.fif',\n",
    "               'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub21\\\\sub21_music-and-reporting_p6-or-p2-epo.fif'\n",
    "]\n",
    "\n",
    "for epoch_file in epoch_files:\n",
    "    # Load the epoch\n",
    "    epochs = mne.read_epochs(epoch_file, preload=True)\n",
    "    \n",
    "    # Check if the channels of interest are present in the data\n",
    "    channels_of_interest = ['ft_valance', 'ft_arousal', 'music']\n",
    "    available_channels = [ch for ch in channels_of_interest if ch in epochs.ch_names]\n",
    "    \n",
    "    # Plot the data for each channel of interest\n",
    "    for ch in available_channels:\n",
    "        # Retrieve the data and times\n",
    "        data = epochs.get_data(picks=ch)\n",
    "        times = epochs.times\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        plt.plot(times, data[0, 0, :])  # Plotting the first epoch's data for the channel\n",
    "        plt.title(f\"{ch} for {os.path.basename(epoch_file)}\")\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Value')\n",
    "        plt.xticks(np.arange(min(times)*1000, (max(times)+0.1)*1000, 100))  # For every 100 milliseconds\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "layout to troubleshoot discrepancy in valance/arousal plots on our end vs. the article's Results Figure 2\n",
    "1) Check the range of 'ft_valance' and 'ft_arousal' values across all subjects and trials to understand the current scaling.\n",
    "2) If the values do not range from 0 to 1, calculate the scaling factor needed to adjust them to this range.\n",
    "3) Apply the scaling factor to the 'ft_valance' and 'ft_arousal' values in your plots to ensure they match the expected scale.\n",
    "\n",
    "read the EDF file header\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1)\n",
    "# script that iterates over each subject, loads their EDF file, and extracts the 'ft_valance' and 'ft_arousal' data to find the minimum and maximum values across all subjects and trials. \n",
    "# give us a better understanding of the scale of these values and whether they need to be adjusted to match the expected 0-1 range.\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "# Define subjects and their raw file paths\n",
    "selected_subjects = ['02', '04', '05', '10', '17', '19', '21']\n",
    "\n",
    "raw_file_paths = {\n",
    "    '02': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-02\\\\eeg\\\\sub-02_task-classicalMusic_eeg.edf',\n",
    "    '04': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-04\\\\eeg\\\\sub-04_task-classicalMusic_eeg.edf',\n",
    "    '05': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-05\\\\eeg\\\\sub-05_task-classicalMusic_eeg.edf',\n",
    "    '10': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-10\\\\eeg\\\\sub-10_task-classicalMusic_eeg.edf',\n",
    "    '17': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-17\\\\eeg\\\\sub-17_task-classicalMusic_eeg.edf',\n",
    "    '19': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-19\\\\eeg\\\\sub-19_task-classicalMusic_eeg.edf',\n",
    "    '21': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-21\\\\eeg\\\\sub-21_task-classicalMusic_eeg.edf'\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize variables to track the min and max values\n",
    "valance_min, valance_max = np.inf, -np.inf\n",
    "arousal_min, arousal_max = np.inf, -np.inf\n",
    "\n",
    "# Loop over each subject\n",
    "for subject in selected_subjects:\n",
    "    # Load the raw data\n",
    "    raw_file_path = raw_file_paths[subject]\n",
    "    raw = mne.io.read_raw_edf(raw_file_path, preload=True)\n",
    "    \n",
    "    # Extract the 'ft_valance' and 'ft_arousal' data\n",
    "    ft_valance_data = raw.copy().pick_channels(['ft_valance']).get_data()\n",
    "    ft_arousal_data = raw.copy().pick_channels(['ft_arousal']).get_data()\n",
    "    \n",
    "    # Update the min and max values if necessary\n",
    "    valance_min = min(valance_min, ft_valance_data.min())\n",
    "    valance_max = max(valance_max, ft_valance_data.max())\n",
    "    arousal_min = min(arousal_min, ft_arousal_data.min())\n",
    "    arousal_max = max(arousal_max, ft_arousal_data.max())\n",
    "\n",
    "# Print out the min and max values\n",
    "print(f\"Valance range: {valance_min} to {valance_max}\")\n",
    "print(f\"Arousal range: {arousal_min} to {arousal_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the EDF file header \n",
    "\n",
    "import mne\n",
    "\n",
    "# Choose a subject and its raw file path for demonstration\n",
    "subject = '02'\n",
    "raw_file_path = raw_file_paths[subject]\n",
    "\n",
    "# Read the EDF file\n",
    "raw = mne.io.read_raw_edf(raw_file_path, preload=False, verbose=False)\n",
    "\n",
    "# Display the info attribute of the Raw object\n",
    "print(raw.info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract specific header details for channels\n",
    "for ch in raw.info['chs']:\n",
    "    print(f\"Channel: {ch['ch_name']}\")\n",
    "    print(f\"  Scaling factor: {ch['cal']}\")\n",
    "    print(f\"  Physical range: {ch['range']}\")\n",
    "    print(f\"  Channel type: {ch['kind']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)-3) \n",
    "# since scaling value of 1.0, use the following function rescale to the article's range of -5 to 5\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "# Define subjects and their raw file paths\n",
    "selected_subjects = ['02', '04', '05', '10', '17', '19', '21']\n",
    "\n",
    "raw_file_paths = {\n",
    "    '02': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-02\\\\eeg\\\\sub-02_task-classicalMusic_eeg.edf',\n",
    "    '04': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-04\\\\eeg\\\\sub-04_task-classicalMusic_eeg.edf',\n",
    "    '05': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-05\\\\eeg\\\\sub-05_task-classicalMusic_eeg.edf',\n",
    "    '10': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-10\\\\eeg\\\\sub-10_task-classicalMusic_eeg.edf',\n",
    "    '17': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-17\\\\eeg\\\\sub-17_task-classicalMusic_eeg.edf',\n",
    "    '19': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-19\\\\eeg\\\\sub-19_task-classicalMusic_eeg.edf',\n",
    "    '21': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-21\\\\eeg\\\\sub-21_task-classicalMusic_eeg.edf'\n",
    "}\n",
    "\n",
    "def rescale_to_range(values, min_value, max_value):\n",
    "    \"\"\"\n",
    "    Rescale values to a given range.\n",
    "    \n",
    "    Args:\n",
    "    - values (array-like): The values to be rescaled.\n",
    "    - min_value (float): The minimum value of the new range.\n",
    "    - max_value (float): The maximum value of the new range.\n",
    "    \n",
    "    Returns:\n",
    "    - np.array: Rescaled values.\n",
    "    \"\"\"\n",
    "    # Normalize to 0-1 range\n",
    "    normalized_values = (values - np.min(values)) / (np.max(values) - np.min(values))\n",
    "    \n",
    "    # Rescale to desired range\n",
    "    rescaled_values = (max_value - min_value) * normalized_values + min_value\n",
    "    \n",
    "    return rescaled_values\n",
    "\n",
    "# Extract and rescale valence and arousal values for each subject and trial\n",
    "rescaled_data = {}\n",
    "\n",
    "channels_of_interest = ['ft_valance', 'ft_arousal']\n",
    "\n",
    "for subject, raw_file_path in raw_file_paths.items():\n",
    "    # Load the raw data\n",
    "    raw = mne.io.read_raw_edf(raw_file_path, preload=True, verbose=False)\n",
    "    \n",
    "    # Diagnostic check: Check channels in raw data\n",
    "    print(f\"Channels in raw data for subject {subject}: {raw.ch_names}\")\n",
    "    \n",
    "    # Extract data for channels of interest\n",
    "    data = raw.copy().pick(channels_of_interest).get_data()\n",
    "    valance_data = data[0]\n",
    "    arousal_data = data[1]\n",
    "    \n",
    "    rescaled_valance = rescale_to_range(valance_data, -5, 5)\n",
    "    rescaled_arousal = rescale_to_range(arousal_data, -5, 5)\n",
    "    \n",
    "    rescaled_data[subject] = {\n",
    "        'valance': rescaled_valance,\n",
    "        'arousal': rescaled_arousal\n",
    "    }\n",
    "\n",
    "print(rescaled_data['02']['valance'][:10], rescaled_data['02']['arousal'][:10])  # Displaying first 10 values for subject 02 as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above: success! now, use in below code for visual inspections before DL, downstream analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeltrace_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subjects and their raw file paths\n",
    "selected_subjects = ['02', '04', '05', '10', '17', '19', '21']\n",
    "\n",
    "raw_file_paths = {\n",
    "    '02': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-02\\\\eeg\\\\sub-02_task-classicalMusic_eeg.edf',\n",
    "    '04': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-04\\\\eeg\\\\sub-04_task-classicalMusic_eeg.edf',\n",
    "    '05': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-05\\\\eeg\\\\sub-05_task-classicalMusic_eeg.edf',\n",
    "    '10': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-10\\\\eeg\\\\sub-10_task-classicalMusic_eeg.edf',\n",
    "    '17': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-17\\\\eeg\\\\sub-17_task-classicalMusic_eeg.edf',\n",
    "    '19': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-19\\\\eeg\\\\sub-19_task-classicalMusic_eeg.edf',\n",
    "    '21': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-21\\\\eeg\\\\sub-21_task-classicalMusic_eeg.edf'\n",
    "}\n",
    "events_dict = {\n",
    "    '02': [[start_trial_1_sub02, 0, 1], [end_trial_1_sub02, 0, 2], [start_trial_2_sub02, 0, 1], [end_trial_2_sub02, 0, 2]],\n",
    "    '04': [[start_trial_2_sub04, 0, 1], [end_trial_2_sub04, 0, 2], [start_trial_3_sub04, 0, 1], [end_trial_3_sub04, 0, 2], [start_trial_5_sub04, 0, 1], [end_trial_5_sub04, 0, 2], [start_trial_8_sub04, 0, 1], [end_trial_8_sub04, 0, 2]],\n",
    "    '05': [[start_trial_1_sub05, 0, 1], [end_trial_1_sub05, 0, 2], [start_trial_3_sub05, 0, 1], [end_trial_3_sub05, 0, 2], [start_trial_7_sub05, 0, 1], [end_trial_7_sub05, 0, 2], [start_trial_9_sub05, 0, 1], [end_trial_9_sub05, 0, 2]],\n",
    "    '10': [[start_trial_1_sub10, 0, 1], [end_trial_1_sub10, 0, 2], [start_trial_4_sub10, 0, 1], [end_trial_4_sub10, 0, 2], [start_trial_6_sub10, 0, 1], [end_trial_6_sub10, 0, 2], [start_trial_8_sub10, 0, 1], [end_trial_8_sub10, 0, 2]],\n",
    "    '17': [[start_trial_1_sub17, 0, 1], [end_trial_1_sub17, 0, 2], [start_trial_2_sub17, 0, 1], [end_trial_2_sub17, 0, 2], [start_trial_5_sub17, 0, 1], [end_trial_5_sub17, 0, 2], [start_trial_6_sub17, 0, 1], [end_trial_6_sub17, 0, 2]],\n",
    "    '19': [[start_trial_2_sub19, 0, 1], [end_trial_2_sub19, 0, 2], [start_trial_4_sub19, 0, 1], [end_trial_4_sub19, 0, 2], [start_trial_5_sub19, 0, 1], [end_trial_5_sub19, 0, 2], [start_trial_8_sub19, 0, 1], [end_trial_8_sub19, 0, 2]],\n",
    "    '21': [[start_trial_2_sub21, 0, 1], [end_trial_2_sub21, 0, 2], [start_trial_4_sub21, 0, 1], [end_trial_4_sub21, 0, 2], [start_trial_5_sub21, 0, 1], [end_trial_5_sub21, 0, 2], [start_trial_8_sub21, 0, 1], [end_trial_8_sub21, 0, 2]],\n",
    "}\n",
    "\n",
    "channels_of_interest = ['ft_valance', 'ft_arousal', 'music']\n",
    "\n",
    "# Rescaling function\n",
    "def rescale_to_range(data, new_min, new_max):\n",
    "    old_min, old_max = np.min(data), np.max(data)\n",
    "    return new_min + (data - old_min) * (new_max - new_min) / (old_max - old_min)\n",
    "\n",
    "for subject in selected_subjects:\n",
    "    # Load the raw data\n",
    "    raw_file_path = raw_file_paths[subject]\n",
    "    raw = mne.io.read_raw_edf(raw_file_path, preload=True)\n",
    "    \n",
    "    # Rescale channels of interest\n",
    "    for ch in channels_of_interest:\n",
    "        if ch in raw.ch_names:\n",
    "            data = raw.copy().pick(ch).get_data()[0]\n",
    "            if ch == 'music':\n",
    "                rescaled_data = rescale_to_range(data, 0, 4)\n",
    "            else:\n",
    "                rescaled_data = rescale_to_range(data, -5, 5)\n",
    "            raw._data[raw.ch_names.index(ch)] = rescaled_data\n",
    "    \n",
    "    # Diagnostic check 1: Check channels in raw data\n",
    "    print(f\"Channels in raw data for subject {subject}: {raw.ch_names}\")\n",
    "    \n",
    "    # Extract events for the current subject from the events_dict\n",
    "    events = events_dict[subject]\n",
    "    trial_starts = [event[0] for event in events if event[2] == 1]\n",
    "    trial_ends = [event[0] for event in events if event[2] == 2]\n",
    "    tmax_values = [(end - start) / raw.info['sfreq'] for start, end in zip(trial_starts, trial_ends)]\n",
    "    \n",
    "    feeltrace_values = []\n",
    "    \n",
    "    for i, start in enumerate(trial_starts):\n",
    "        musicandreporting_trialsegs = mne.Epochs(raw, events=[events[i*2]], event_id={'start': 1}, tmin=0, tmax=tmax_values[i], baseline=None, preload=True)\n",
    "        \n",
    "        # Extract FEELTRACE values for the segment\n",
    "        valance_data = musicandreporting_trialsegs.get_data(picks='ft_valance')[0]\n",
    "        arousal_data = musicandreporting_trialsegs.get_data(picks='ft_arousal')[0]\n",
    "    \n",
    "        # Append the time-series values to our list\n",
    "        feeltrace_values.append([valance_data, arousal_data])\n",
    "        \n",
    "        # Diagnostic check 2: Check channels in epochs_temp\n",
    "        print(f\"Channels in musicandreporting_trialsegs for subject {subject}, trial {i+1}: {musicandreporting_trialsegs.ch_names}\")\n",
    "        \n",
    "        for ch in channels_of_interest:\n",
    "            if ch in musicandreporting_trialsegs.ch_names:\n",
    "                data = musicandreporting_trialsegs.get_data(picks=ch)[0]\n",
    "                times = musicandreporting_trialsegs.times\n",
    "                                \n",
    "                # Plot\n",
    "                plt.figure(figsize=(15, 4))\n",
    "                plt.plot(times, data[-1, :])  \n",
    "                plt.title(f\"Subject: {subject} | Channel: {ch} | Trial {i+1}\")\n",
    "                plt.xlabel('Time (s)')\n",
    "                plt.ylabel('Value')\n",
    "                \n",
    "                # Set x-axis ticks for every 10 seconds\n",
    "                x_ticks = np.arange(times[0], times[-1], 10)\n",
    "                plt.xticks(x_ticks, [f\"{tick:.2f}\" for tick in x_ticks])\n",
    "                plt.grid(True)\n",
    "                plt.tight_layout()\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# section 6: epoching for musical phrases, then musical moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# section 6 sample numbers for phrases and moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject 2's sample numbers for musical phrases and moments\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-02\\\\eeg\\\\sub-02_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "sfreq = raw.info['sfreq']  # get the sampling frequency\n",
    "\n",
    "\n",
    "# pieces\n",
    "start_piece3_sub02 = int(17.092 * sfreq)\n",
    "end_piece3_sub02= int(167.092 * sfreq)\n",
    "\n",
    "start_piece2_sub02 = int(175.484 * sfreq)\n",
    "end_piece2_sub02= int(302.484 * sfreq)\n",
    "\n",
    "# phrases\n",
    "start_phrase1_sub02_p3 = int(125.092 * sfreq)\n",
    "end_phrase1_sub02_p3= int(147.092 * sfreq)\n",
    "\n",
    "start_phrase2_sub02_p2 = int(175.484 * sfreq)\n",
    "end_phrase2_sub02_p2= int(197.484 * sfreq)\n",
    "\n",
    "# moment within each phrase, piece numbers correpsond\n",
    "#start_moment_1_sub02_p3 = int(128.092 * sfreq)\n",
    "#end_moment_1_sub02_p3 = int(129.092 * sfreq)\n",
    "\n",
    "#start_moment_2_sub02_p2 = int(194.484 * sfreq)\n",
    "#end_moment_2_sub02_p2 = int(195.484 * sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject 4's sample numbers for musical phrases and moments\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-04\\\\eeg\\\\sub-04_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "sfreq = raw.info['sfreq']  # get the sampling frequency\n",
    "\n",
    "# pieces\n",
    "start_piece3_sub04 = int(605.756 * sfreq)\n",
    "end_piece3_sub04= int(755.756 * sfreq)\n",
    "\n",
    "start_piece2_sub04 = int(337.511 * sfreq)\n",
    "end_piece2_sub04= int(464.511 * sfreq)\n",
    "\n",
    "start_piece5_sub04 = int(173.555 * sfreq)\n",
    "end_piece5_sub04= int(333.555 * sfreq)\n",
    "\n",
    "# phrases\n",
    "start_phrase1_sub04_p3 = int(713.756 * sfreq)\n",
    "end_phrase1_sub04_p3= int(735.756 * sfreq)\n",
    "\n",
    "start_phrase2_sub04_p2 = int(337.511 * sfreq)\n",
    "end_phrase2_sub04_p2= int(359.511 * sfreq)\n",
    "\n",
    "start_phrase3_sub04_p5 = int(213.555 * sfreq)\n",
    "end_phrase3_sub04_p5= int(228.555 * sfreq)\n",
    "\n",
    "# moment within each phrase, piece numbers correpsond\n",
    "#start_moment_1_sub04_p3 = int(716.756 * sfreq)\n",
    "#end_moment_1_sub04_p3 = int(717.756 * sfreq)\n",
    "\n",
    "#start_moment_2_sub04_p2 = int(356.511 * sfreq)\n",
    "#end_moment_2_sub04_p2 = int(357.511 * sfreq)\n",
    "\n",
    "#start_moment_3_sub04_p5 = int(227.555 * sfreq)\n",
    "#end_moment_3_sub04_p5 = int(228.555 * sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject 5's sample numbers for musical phrases and moments\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-05\\\\eeg\\\\sub-05_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "sfreq = raw.info['sfreq']  # get the sampling frequency\n",
    "\n",
    "# pieces\n",
    "start_piece3_sub05 = int(908.811 * sfreq)\n",
    "end_piece3_sub05= int(1058.811 * sfreq)\n",
    "\n",
    "start_piece2_sub05 = int(14.594 * sfreq)\n",
    "end_piece2_sub05= int(141.594 * sfreq)\n",
    "\n",
    "start_piece5_sub05 = int(282.772 * sfreq)\n",
    "end_piece5_sub05= int(442.772 * sfreq)\n",
    "\n",
    "# phrases\n",
    "start_phrase1_sub05_p3 = int(1016.811 * sfreq)\n",
    "end_phrase1_sub05_p3= int(1038.811 * sfreq)\n",
    "\n",
    "start_phrase2_sub05_p2 = int(14.594 * sfreq)\n",
    "end_phrase2_sub05_p2= int(36.594 * sfreq)\n",
    "\n",
    "start_phrase3_sub05_p5 = int(322.722 * sfreq)\n",
    "end_phrase3_sub05_p5= int(337.772 * sfreq)\n",
    "\n",
    "# moment within each phrase, piece numbers correpsond\n",
    "#start_moment_1_sub05_p3 = int(1019.811 * sfreq)\n",
    "#end_moment_1_sub05_p3 = int(1020.811 * sfreq)\n",
    "\n",
    "#start_moment_2_sub05_p2 = int(33.594 * sfreq)\n",
    "#end_moment_2_sub05_p2 = int(34.594 * sfreq)\n",
    "\n",
    "#start_moment_3_sub05_p5 = int(336.772 * sfreq)\n",
    "#end_moment_3_sub05_p5 = int(337.772 * sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject 10's sample numbers for musical phrases and moments\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-10\\\\eeg\\\\sub-10_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "sfreq = raw.info['sfreq']  # get the sampling frequency\n",
    "\n",
    "# pieces\n",
    "start_piece3_sub10 = int(447.09 * sfreq)\n",
    "end_piece3_sub10= int(597.09 * sfreq)\n",
    "\n",
    "start_piece2_sub10 = int(14.906 * sfreq)\n",
    "end_piece2_sub10= int(141.906 * sfreq)\n",
    "\n",
    "start_piece5_sub10 = int(1089.656 * sfreq)\n",
    "end_piece5_sub10= int(1249.656 * sfreq)\n",
    "\n",
    "# phrases\n",
    "start_phrase1_sub10_p3 = int(555.09 * sfreq)\n",
    "end_phrase1_sub10_p3= int(577.09 * sfreq)\n",
    "\n",
    "start_phrase2_sub10_p2 = int(14.906 * sfreq)\n",
    "end_phrase2_sub10_p2= int(36.906 * sfreq)\n",
    "\n",
    "start_phrase3_sub10_p5 = int(1129.656 * sfreq)\n",
    "end_phrase3_sub10_p5= int(1144.656 * sfreq)\n",
    "\n",
    "# moment within each phrase, piece numbers correpsond\n",
    "#start_moment_1_sub10_p3 = int(558.09 * sfreq)\n",
    "#end_moment_1_sub10_p3 = int(559.09 * sfreq)\n",
    "\n",
    "#start_moment_2_sub10_p2 = int(33.906 * sfreq)\n",
    "#end_moment_2_sub10_p2 = int(34.906 * sfreq)\n",
    "\n",
    "#start_moment_3_sub10_p5 = int(1143.656 * sfreq)\n",
    "#end_moment_3_sub10_p5 = int(1144.656 * sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject 17's sample numbers for musical phrases and moments\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-17\\\\eeg\\\\sub-17_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "sfreq = raw.info['sfreq']  # get the sampling frequency\n",
    "\n",
    "# pieces\n",
    "start_piece3_sub17 = int(14.109 * sfreq)\n",
    "end_piece3_sub17= int(164.109 * sfreq)\n",
    "\n",
    "start_piece2_sub17 = int(791.817 * sfreq)\n",
    "end_piece2_sub17= int(918.817 * sfreq)\n",
    "\n",
    "start_piece5_sub17 = int(628.262 * sfreq)\n",
    "end_piece5_sub17= int(788.262 * sfreq)\n",
    "\n",
    "# phrases\n",
    "start_phrase1_sub17_p3 = int(122.109 * sfreq)\n",
    "end_phrase1_sub17_p3= int(144.109 * sfreq)\n",
    "\n",
    "start_phrase2_sub17_p2 = int(791.817 * sfreq)\n",
    "end_phrase2_sub17_p2= int(813.817 * sfreq)\n",
    "\n",
    "start_phrase3_sub17_p5 = int(668.262 * sfreq)\n",
    "end_phrase3_sub17_p5= int(683.262 * sfreq)\n",
    "\n",
    "# moment within each phrase, piece numbers correpsond\n",
    "#start_moment_1_sub17_p3 = int(125.109 * sfreq)\n",
    "#end_moment_1_sub17_p3 = int(126.109 * sfreq)\n",
    "\n",
    "#start_moment_2_sub17_p2 = int(810.817 * sfreq)\n",
    "#end_moment_2_sub17_p2 = int(811.817 * sfreq)\n",
    "\n",
    "#start_moment_3_sub17_p5 = int(682.262 * sfreq)\n",
    "#end_moment_3_sub17_p5 = int(683.262 * sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject 19's sample numbers for musical phrases and moments\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-19\\\\eeg\\\\sub-19_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "sfreq = raw.info['sfreq']  # get the sampling frequency\n",
    "\n",
    "# pieces\n",
    "start_piece3_sub19 = int(637.032 * sfreq)\n",
    "end_piece3_sub19= int(787.032 * sfreq)\n",
    "\n",
    "start_piece2_sub19 = int(502.826 * sfreq)\n",
    "end_piece2_sub19= int(629.826 * sfreq)\n",
    "\n",
    "start_piece5_sub19 = int(1124.542 * sfreq)\n",
    "end_piece5_sub19= int(1284.542 * sfreq)\n",
    "\n",
    "# phrases\n",
    "start_phrase1_sub19_p3 = int(745.032 * sfreq)\n",
    "end_phrase1_sub19_p3= int(767.032 * sfreq)\n",
    "\n",
    "start_phrase2_sub19_p2 = int(502.826 * sfreq)\n",
    "end_phrase2_sub19_p2= int(524.826 * sfreq)\n",
    "\n",
    "start_phrase3_sub19_p5 = int(1161.608 * sfreq)\n",
    "end_phrase3_sub19_p5= int(1176.608 * sfreq)\n",
    "\n",
    "# moment within each phrase, piece numbers correpsond\n",
    "#start_moment_1_sub19_p3 = int(748.032 * sfreq)\n",
    "#end_moment_1_sub19_p3 = int(749.032 * sfreq)\n",
    "\n",
    "#start_moment_2_sub19_p2 = int(521.826 * sfreq)\n",
    "#end_moment_2_sub19_p2 = int(522.826 * sfreq)\n",
    "\n",
    "#start_moment_3_sub19_p5 = int(1175.608 * sfreq)\n",
    "#end_moment_3_sub19_p5 = int(1176.608 * sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject 21's sample numbers for musical phrases and moments\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-21\\\\eeg\\\\sub-21_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "sfreq = raw.info['sfreq']  # get the sampling frequency\n",
    "\n",
    "# pieces\n",
    "start_piece3_sub21 = int(636.067 * sfreq)\n",
    "end_piece3_sub21= int(786.067 * sfreq)\n",
    "\n",
    "start_piece2_sub21 = int(502.01 * sfreq)\n",
    "end_piece2_sub21= int(629.01 * sfreq)\n",
    "\n",
    "start_piece5_sub21 = int(1121.608 * sfreq)\n",
    "end_piece5_sub21= int(1281.608 * sfreq)\n",
    "\n",
    "# phrases\n",
    "start_phrase1_sub21_p3 = int(744.067 * sfreq)\n",
    "end_phrase1_sub21_p3= int(766.067 * sfreq)\n",
    "\n",
    "start_phrase2_sub21_p2 = int(502.01 * sfreq)\n",
    "end_phrase2_sub21_p2= int(524.01 * sfreq)\n",
    "\n",
    "start_phrase3_sub21_p5 = int(1161.608 * sfreq)\n",
    "end_phrase3_sub21_p5= int(1176.608 * sfreq)\n",
    "\n",
    "# moment within each phrase, piece numbers correpsond\n",
    "#start_moment_1_sub21_p3 = int(747.067 * sfreq)\n",
    "#end_moment_1_sub21_p3 = int(748.067 * sfreq)\n",
    "\n",
    "#start_moment_2_sub21_p2 = int(521.01 * sfreq)\n",
    "#end_moment_2_sub21_p2 = int(524.01 * sfreq)\n",
    "\n",
    "#start_moment_3_sub21_p5 = int(1175.608 * sfreq)\n",
    "#end_moment_3_sub21_p5 = int(1176.608 * sfreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# section 6 epoching/segmenting for musical phrases, moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for EEG data epoched/segmented into pieces & phrases, respectively\n",
    "# USE processed-for-analysis AS PATH!\n",
    "\n",
    "import os\n",
    "import mne\n",
    "\n",
    "# Generic function to save epochs for musical segments (phrases or moments)\n",
    "def save_epochs_for_segments(subject, start_end_samples, raw, output_folder, segment_type):\n",
    "    \"\"\"Saves epochs for each musical segment (phrase or moment) based on start and end samples.\"\"\"\n",
    "    subject_folder = os.path.join(output_folder, subject)\n",
    "    if not os.path.exists(subject_folder):\n",
    "        os.makedirs(subject_folder)\n",
    "    \n",
    "    for i, (start, end) in enumerate(start_end_samples):\n",
    "        epochs = mne.Epochs(raw, events=[[start, 0, 1], [end, 0, 2]], event_id={segment_type: 1},\n",
    "                            tmin=0, tmax=(end - start) / raw.info['sfreq'], baseline=None, preload=True)\n",
    "        epochs.save(os.path.join(subject_folder, f\"{subject}_musical{segment_type}_{i+1}-epo.fif\"), overwrite=True)\n",
    "\n",
    "\n",
    "# use the processed-for-analysis, not raw, for this 'raw_file_paths' variable\n",
    "raw_file_paths = {\n",
    "    '02': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\processed-for-analysis\\\\sub-02_task-classicalMusic_eeg_raw-with-ICA-weights-filtered-and-referenced_analysis.fif',\n",
    "    '04': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\processed-for-analysis\\\\sub-04_task-classicalMusic_eeg_raw-with-ICA-weights-filtered-and-referenced_analysis.fif',\n",
    "    '05': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\processed-for-analysis\\\\sub-05_task-classicalMusic_eeg_raw-with-ICA-weights-filtered-and-referenced_analysis.fif',\n",
    "    '10': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\processed-for-analysis\\\\sub-10_task-classicalMusic_eeg_raw-with-ICA-weights-filtered-and-referenced_analysis.fif',\n",
    "    '17': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\processed-for-analysis\\\\sub-17_task-classicalMusic_eeg_raw-with-ICA-weights-filtered-and-referenced_analysis.fif',\n",
    "    '19': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\processed-for-analysis\\\\sub-19_task-classicalMusic_eeg_raw-with-ICA-weights-filtered-and-referenced_analysis.fif',\n",
    "    '21': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\processed-for-analysis\\\\sub-21_task-classicalMusic_eeg_raw-with-ICA-weights-filtered-and-referenced_analysis.fif'\n",
    "}\n",
    "\n",
    "# Dictionaries for musical phrases and moments\n",
    "musical_pieces_samples = {\n",
    "    '02': [(start_piece3_sub02, end_piece3_sub02), (start_piece2_sub02, end_piece2_sub02)],\n",
    "    '04': [(start_piece3_sub04, end_piece3_sub04), (start_piece2_sub04, end_piece2_sub04), (start_piece5_sub04, end_piece5_sub04)],\n",
    "    '05': [(start_piece3_sub05, end_piece3_sub05), (start_piece2_sub05, end_piece2_sub05), (start_piece5_sub05, end_piece5_sub05)],\n",
    "    '10': [(start_piece3_sub10, end_piece3_sub10), (start_piece2_sub10, end_piece2_sub10), (start_piece5_sub10, end_piece5_sub10)],\n",
    "    '17': [(start_piece3_sub17, end_piece3_sub17), (start_piece2_sub17, end_piece2_sub17), (start_piece5_sub17, end_piece5_sub17)],\n",
    "    '19': [(start_piece3_sub19, end_piece3_sub19), (start_piece2_sub19, end_piece2_sub19), (start_piece5_sub19, end_piece5_sub19)], \n",
    "    '21': [(start_piece3_sub21, end_piece3_sub21), (start_piece2_sub21, end_piece2_sub21), (start_piece5_sub21, end_piece5_sub21)]\n",
    "}\n",
    "musical_phrases_samples = {\n",
    "    '02': [(start_phrase1_sub02_p3, end_phrase1_sub02_p3), (start_phrase2_sub02_p2, end_phrase2_sub02_p2)],\n",
    "    '04': [(start_phrase1_sub04_p3, end_phrase1_sub04_p3), (start_phrase2_sub04_p2, end_phrase2_sub04_p2), (start_phrase3_sub04_p5, end_phrase3_sub04_p5)],\n",
    "    '05': [(start_phrase1_sub05_p3, end_phrase1_sub05_p3), (start_phrase2_sub05_p2, end_phrase2_sub05_p2), (start_phrase3_sub05_p5, end_phrase3_sub05_p5)],\n",
    "    '10': [(start_phrase1_sub10_p3, end_phrase1_sub10_p3), (start_phrase2_sub10_p2, end_phrase2_sub10_p2), (start_phrase3_sub10_p5, end_phrase3_sub10_p5)],\n",
    "    '17': [(start_phrase1_sub17_p3, end_phrase1_sub17_p3), (start_phrase2_sub17_p2, end_phrase2_sub17_p2), (start_phrase3_sub17_p5, end_phrase3_sub17_p5)],\n",
    "    '19': [(start_phrase1_sub19_p3, end_phrase1_sub19_p3), (start_phrase2_sub19_p2, end_phrase2_sub19_p2), (start_phrase3_sub19_p5, end_phrase3_sub19_p5)], \n",
    "    '21': [(start_phrase1_sub21_p3, end_phrase1_sub21_p3), (start_phrase2_sub21_p2, end_phrase2_sub21_p2), (start_phrase3_sub21_p5, end_phrase3_sub21_p5)]\n",
    "}\n",
    "\n",
    "#musical_moments_samples = {\n",
    "    #'02': [(start_moment_1_sub02_p3, end_moment_1_sub02_p3), (start_moment_2_sub02_p2, end_moment_2_sub02_p2)],\n",
    "    #'04': [(start_moment_1_sub04_p3, end_moment_1_sub04_p3), (start_moment_2_sub04_p2, end_moment_2_sub04_p2), (start_moment_3_sub04_p5, end_moment_3_sub04_p5)],\n",
    "    #'05': [(start_moment_1_sub05_p3, end_moment_1_sub05_p3), (start_moment_2_sub05_p2, end_moment_2_sub05_p2), (start_moment_3_sub05_p5, end_moment_3_sub05_p5)],\n",
    "    #'10': [(start_moment_1_sub10_p3, end_moment_1_sub10_p3), (start_moment_2_sub10_p2, end_moment_2_sub10_p2), (start_moment_3_sub10_p5, end_moment_3_sub10_p5)],\n",
    "    #'17': [(start_moment_1_sub17_p3, end_moment_1_sub17_p3), (start_moment_2_sub17_p2, end_moment_2_sub17_p2), (start_moment_3_sub17_p5, end_moment_3_sub17_p5)],\n",
    "    #'19': [(start_moment_1_sub19_p3, end_moment_1_sub19_p3), (start_moment_2_sub19_p2, end_moment_2_sub19_p2), (start_moment_3_sub19_p5, end_moment_3_sub19_p5)], \n",
    "    #'21': [(start_moment_1_sub21_p3, end_moment_1_sub21_p3), (start_moment_2_sub21_p2, end_moment_2_sub21_p2), (start_moment_3_sub21_p5, end_moment_3_sub21_p5)]\n",
    "#}\n",
    "\n",
    "# Folder structure\n",
    "musicalpieces_output_folder = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data'\n",
    "# Create the musical moments output folder if it doesn't exist\n",
    "if not os.path.exists(musicalmoments_output_folder):\n",
    "    os.makedirs(musicalmoments_output_folder, exist_ok=True)\n",
    "\n",
    "musicalphrases_output_folder = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data'\n",
    "# Create the musical phrases output folder if it doesn't exist\n",
    "if not os.path.exists(musicalphrases_output_folder):\n",
    "    os.makedirs(musicalphrases_output_folder, exist_ok=True)\n",
    "\n",
    "# Load the processed data and save epochs for phrases and moments\n",
    "for subject, start_end_samples in musical_pieces_samples.items():\n",
    "    processed_raw = mne.io.read_raw_fif(raw_file_paths[subject], preload=True)\n",
    "    save_epochs_for_segments(subject, start_end_samples, processed_raw, musicalpieces_output_folder, 'piece')\n",
    "\n",
    "for subject, start_end_samples in musical_phrases_samples.items():\n",
    "    processed_raw = mne.io.read_raw_fif(raw_file_paths[subject], preload=True)\n",
    "    save_epochs_for_segments(subject, start_end_samples, processed_raw, musicalphrases_output_folder, 'phrase')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Let's say you have 100 epochs, 32 channels, and 1000 timepoints per epoch\n",
    "# This is your three-dimensional EEG data array:\n",
    "eeg_data = np.random.rand(100, 32, 1000)  # Replace with your actual EEG data\n",
    "\n",
    "# Reshape the data to two dimensions: (n_samples, n_features)\n",
    "# This flattens the last two dimensions\n",
    "eeg_data_reshaped = eeg_data.reshape(100, -1)  # Now of shape (100, 32000)\n",
    "\n",
    "# It's often a good idea to scale the features\n",
    "scaler = StandardScaler()\n",
    "eeg_data_scaled = scaler.fit_transform(eeg_data_reshaped)\n",
    "\n",
    "# Now you can use eeg_data_scaled with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE, LocallyLinearEmbedding, Isomap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "eeg_tsne = tsne.fit_transform(eeg_data_scaled)\n",
    "\n",
    "# LLE\n",
    "lle = LocallyLinearEmbedding(n_components=2, random_state=42)\n",
    "eeg_lle = lle.fit_transform(eeg_data_scaled)\n",
    "\n",
    "# Isomap\n",
    "isomap = Isomap(n_components=2)\n",
    "eeg_isomap = isomap.fit_transform(eeg_data_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the piece and phrase visualizations, respectively\n",
    "# USE RAW EEG FILE AS PATH\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "# Define paths to the processed epochs and the raw EEG files\n",
    "processed_epochs_paths = {\n",
    "    '02': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_2-epo.fif',\n",
    "    ],\n",
    "    '04': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '05': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '10': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '17': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '19': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '21': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "}\n",
    "\n",
    "raw_file_paths = {\n",
    "    '02': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-02\\\\eeg\\\\sub-02_task-classicalMusic_eeg.edf',\n",
    "    '04': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-04\\\\eeg\\\\sub-04_task-classicalMusic_eeg.edf',\n",
    "    '05': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-05\\\\eeg\\\\sub-05_task-classicalMusic_eeg.edf',\n",
    "    '10': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-10\\\\eeg\\\\sub-10_task-classicalMusic_eeg.edf',\n",
    "    '17': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-17\\\\eeg\\\\sub-17_task-classicalMusic_eeg.edf',\n",
    "    '19': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-19\\\\eeg\\\\sub-19_task-classicalMusic_eeg.edf',\n",
    "    '21': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-21\\\\eeg\\\\sub-21_task-classicalMusic_eeg.edf'\n",
    "}\n",
    "\n",
    "# Define the output folder for the figures\n",
    "figures_output_folder = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\valencearousal_epochs'\n",
    "# Create the musical phrases output folder if it doesn't exist\n",
    "if not os.path.exists(musicalphrases_output_folder):\n",
    "    os.makedirs(musicalphrases_output_folder, exist_ok=True)\n",
    "\n",
    "    # Function to plot 'ft_valance' and 'ft_arousal' for a given raw segment\n",
    "    def plot_feeltrace_for_segment(raw, start, end, subject, epoch_type, epoch_index):\n",
    "        # Create a segment of the raw data\n",
    "        raw_segment = raw.copy().crop(tmin=start, tmax=end)\n",
    "        \n",
    "        # Plot 'ft_valance' and 'ft_arousal'\n",
    "        for ch in ['ft_valance', 'ft_arousal']:\n",
    "            if ch in raw_segment.ch_names:\n",
    "                data, times = raw_segment.copy().pick_channels([ch]).get_data(return_times=True)\n",
    "                \n",
    "                # Plot\n",
    "                plt.figure(figsize=(15, 4))\n",
    "                plt.plot(times, data[0, :], label=ch)\n",
    "                plt.title(f\"Subject: {subject} | Channel: {ch} | {epoch_type} {epoch_index}\")\n",
    "                plt.xlabel('Time (s)')\n",
    "                plt.ylabel('Value')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # Save the figure\n",
    "                plt.savefig(f\"{figures_output_folder}/Subject_{subject}_{epoch_type}_{epoch_index}_{ch}.png\")\n",
    "                plt.close()  # Close the figure to free memory\n",
    "\n",
    "# Define the rescaling function\n",
    "def rescale_to_range(data, new_min, new_max):\n",
    "    old_min, old_max = np.min(data), np.max(data)\n",
    "    return new_min + (data - old_min) * (new_max - new_min) / (old_max - old_min)\n",
    "\n",
    "# Loop over each subject and their processed epochs\n",
    "for subject, epoch_paths in processed_epochs_paths.items():\n",
    "    for epoch_index, epoch_path in enumerate(epoch_paths):\n",
    "        try:\n",
    "            # Load the processed epochs\n",
    "            epochs = mne.read_epochs(epoch_path, preload=True)\n",
    "            \n",
    "            # Load the raw EEG data\n",
    "            raw = mne.io.read_raw_edf(raw_file_paths[subject], preload=True)\n",
    "            \n",
    "            # Rescale channels of interest\n",
    "            for ch in ['ft_valance', 'ft_arousal']:\n",
    "                if ch in raw.ch_names:\n",
    "                    data = raw.copy().pick(ch).get_data()[0]\n",
    "                    rescaled_data = rescale_to_range(data, -5, 5)\n",
    "                    raw._data[raw.ch_names.index(ch)] = rescaled_data\n",
    "            \n",
    "            # Define start and end times based on epochs events\n",
    "            events = epochs.events\n",
    "            sfreq = raw.info['sfreq']\n",
    "            start_times = events[:, 0] / sfreq\n",
    "            end_times = (events[:, 0] + epochs.times[-1] * sfreq) / sfreq\n",
    "            \n",
    "            # Loop over each epoch's start and end times to plot 'ft_valance' and 'ft_arousal'\n",
    "            for start, end in zip(start_times, end_times):\n",
    "                # Plot 'ft_valance' and 'ft_arousal' for this segment\n",
    "                plot_feeltrace_for_segment(raw, start, end, subject, 'phrase' if 'phrase' in epoch_path else 'piece', epoch_index + 1)\n",
    "                \n",
    "        except OSError as e:\n",
    "            print(f\"An error occurred while reading {epoch_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "processed_epochs_paths = {\n",
    "    '02': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_2-epo.fif',\n",
    "    ],\n",
    "    '04': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '05': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '10': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '17': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '19': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '21': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "}\n",
    "\n",
    "raw_file_paths = {\n",
    "    '02': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-02\\\\eeg\\\\sub-02_task-classicalMusic_eeg.edf',\n",
    "    '04': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-04\\\\eeg\\\\sub-04_task-classicalMusic_eeg.edf',\n",
    "    '05': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-05\\\\eeg\\\\sub-05_task-classicalMusic_eeg.edf',\n",
    "    '10': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-10\\\\eeg\\\\sub-10_task-classicalMusic_eeg.edf',\n",
    "    '17': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-17\\\\eeg\\\\sub-17_task-classicalMusic_eeg.edf',\n",
    "    '19': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-19\\\\eeg\\\\sub-19_task-classicalMusic_eeg.edf',\n",
    "    '21': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-21\\\\eeg\\\\sub-21_task-classicalMusic_eeg.edf'\n",
    "}\n",
    "\n",
    "# Define the output folder for the figures\n",
    "figures_output_folder = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\valencearousal_epochs'\n",
    "# Make sure the output folder exists\n",
    "if not os.path.exists(figures_output_folder):\n",
    "    os.makedirs(figures_output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# Define a function to save epochs and plot FEELTRACE channels\n",
    "def save_and_plot_epochs_for_phrases(subject, start_end_samples, raw, output_folder):\n",
    "    \"\"\"Saves epochs for each musical phrase and plots FEELTRACE channels.\"\"\"\n",
    "    # Create the subject's folder if it doesn't exist\n",
    "    subject_folder = os.path.join(output_folder, subject)\n",
    "    if not os.path.exists(subject_folder):\n",
    "        os.makedirs(subject_folder)\n",
    "    \n",
    "    # Iterate over each start and end time to create, save epochs, and plot FEELTRACE channels\n",
    "    for i, (start, end) in enumerate(start_end_samples):\n",
    "        epochs = mne.Epochs(raw, events=[[start, 0, 1], [end, 0, 2]], event_id={'phrase': 1},\n",
    "                            tmin=0, tmax=(end - start) / raw.info['sfreq'], baseline=None, preload=True)\n",
    "        epochs.save(os.path.join(subject_folder, f\"{subject}_musicalphrase_{i+1}-epo.fif\"), overwrite=True)\n",
    "        \n",
    "        # Extract and plot FEELTRACE channels\n",
    "        valance_data = raw.copy().crop(tmin=start/raw.info['sfreq'], tmax=end/raw.info['sfreq']).pick_channels(['ft_valance'])\n",
    "        arousal_data = raw.copy().crop(tmin=start/raw.info['sfreq'], tmax=end/raw.info['sfreq']).pick_channels(['ft_arousal'])\n",
    "        \n",
    "        # Plot and save the figures\n",
    "        plt.figure()\n",
    "        plt.plot(valance_data.times, valance_data.get_data()[0, :], label='Valance')\n",
    "        plt.plot(arousal_data.times, arousal_data.get_data()[0, :], label='Arousal')\n",
    "        plt.legend()\n",
    "        plt.title(f\"{subject} Musical Phrase {i+1} FEELTRACE\")\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('FEELTRACE Score')\n",
    "        plt.savefig(os.path.join(subject_folder, f\"{subject}_musicalphrase_{i+1}_FEELTRACE.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# Define the start and end samples for musical phrases for each subject\n",
    "# This dictionary will need to be filled with the correct start and end times\n",
    "musical_phrases_samples = {\n",
    "    '02': [(start_trial_1_sub02, end_trial_1_sub02), (start_trial_2_sub02, end_trial_2_sub02), ...], # Fill in with actual values\n",
    "    # Repeat for other subjects...\n",
    "}\n",
    "\n",
    "# Define subjects and their raw file paths (update with the correct paths)\n",
    "raw_file_paths = {\n",
    "    '02': 'path_to_sub02_raw.fif',\n",
    "    # Repeat for other subjects...\n",
    "}\n",
    "\n",
    "# Define the output folder for musical phrases\n",
    "musicalphrases_output_folder = 'path_to_musicalphrases_data_folder'\n",
    "\n",
    "# Load the raw data, save epochs, and plot FEELTRACE channels for each subject\n",
    "for subject, start_end_samples in musical_phrases_samples.items():\n",
    "    raw = mne.io.read_raw_fif(raw_file_paths[subject], preload=True)\n",
    "    save_and_plot_epochs_for_phrases(subject, start_end_samples, raw, musicalphrases_output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# section 7: old parameters; not used in article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20:04 version, update on the color spectrum but still keep previous results for comparing parameters\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "from mne import Epochs, find_events\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.colors as mcolors\n",
    "import re\n",
    "\n",
    "# Define paths to the processed epochs and the raw EEG files\n",
    "processed_epochs_paths = {\n",
    "    '02': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_2-epo.fif',\n",
    "    ],\n",
    "    '04': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '05': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '10': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '17': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '19': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '21': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "}\n",
    "\n",
    "raw_file_paths = {\n",
    "    '02': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-02\\\\eeg\\\\sub-02_task-classicalMusic_eeg.edf',\n",
    "    '04': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-04\\\\eeg\\\\sub-04_task-classicalMusic_eeg.edf',\n",
    "    '05': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-05\\\\eeg\\\\sub-05_task-classicalMusic_eeg.edf',\n",
    "    '10': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-10\\\\eeg\\\\sub-10_task-classicalMusic_eeg.edf',\n",
    "    '17': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-17\\\\eeg\\\\sub-17_task-classicalMusic_eeg.edf',\n",
    "    '19': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-19\\\\eeg\\\\sub-19_task-classicalMusic_eeg.edf',\n",
    "    '21': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-21\\\\eeg\\\\sub-21_task-classicalMusic_eeg.edf'\n",
    "}\n",
    "\n",
    "def create_sub_epochs(epochs, epoch_type):\n",
    "    sub_epochs_data = []\n",
    "    sfreq = epochs.info['sfreq']  # Sampling frequency\n",
    "    \n",
    "    if epoch_type == 'musicalphrase':\n",
    "        sub_epoch_length = 0.1  # 100ms for phrases\n",
    "    elif epoch_type == 'musicalpiece':\n",
    "        sub_epoch_length = 0.5 # 500ms for pieces\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown epoch type: {epoch_type}\")\n",
    "\n",
    "    # Calculate the number of samples for the given sub_epoch_length\n",
    "    sub_epoch_samples = int(sub_epoch_length * sfreq)\n",
    "\n",
    "    # Create sub-epochs\n",
    "    for start_time in np.arange(0, epochs.tmax, sub_epoch_length):\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = start_idx + sub_epoch_samples\n",
    "        if end_idx > len(epochs.times):  # Ensure we don't go past the end\n",
    "            break\n",
    "\n",
    "        # Ensure indices are integers and correct slicing\n",
    "        start_idx = int(start_idx)\n",
    "        end_idx = int(end_idx)\n",
    "        # Append sub-epoch data\n",
    "        sub_epochs_data.append(epochs.copy().crop(tmin=epochs.times[start_idx], tmax=epochs.times[end_idx-1], include_tmax=True))\n",
    "    \n",
    "    return sub_epochs_data\n",
    "\n",
    "def extract_valance_arousal_for_epoch(epoch, raw, valence_channel='ft_valance', arousal_channel='ft_arousal'):\n",
    "    \"\"\"\n",
    "    Extracts valence and arousal data for a given epoch from the raw EDF file.\n",
    "    \n",
    "    :param epoch: The epoch for which to extract valence and arousal\n",
    "    :param raw: The raw EDF data containing valence and arousal channels\n",
    "    :param valence_channel: The name of the valence channel\n",
    "    :param arousal_channel: The name of the arousal channel\n",
    "    :return: A tuple containing the valence and arousal data arrays\n",
    "    \"\"\"\n",
    "    # Get the start and end times of the epoch\n",
    "    start, end = epoch.times[0], epoch.times[-1]\n",
    "    start_sample, end_sample = int(start * raw.info['sfreq']), int(end * raw.info['sfreq'])\n",
    "    \n",
    "    # Extract valence and arousal data for the duration of the epoch\n",
    "    valence_data = raw.copy().pick_channels([valence_channel]).get_data(start=start_sample, stop=end_sample)\n",
    "    arousal_data = raw.copy().pick_channels([arousal_channel]).get_data(start=start_sample, stop=end_sample)\n",
    "    \n",
    "    return valence_data, arousal_data\n",
    "\n",
    "\n",
    "def extract_features(sub_epochs_data, sfreq, epoch_type):\n",
    "    features = []\n",
    "    # Define the frequency bands\n",
    "    bands = {'delta': (0.5, 4), 'theta': (4, 8), 'alpha': (8, 13)}\n",
    "    spectral_features = []\n",
    "    pcc_features = []\n",
    "\n",
    "    # Calculate the number of samples for the given sub_epoch lengths based on the sampling frequency\n",
    "    if epoch_type == 'musicalphrase':\n",
    "        sub_epoch_length = 0.1  # 100ms for phrases\n",
    "        num_samples = int(sub_epoch_length * sfreq)\n",
    "    elif epoch_type == 'musicalpiece':\n",
    "        sub_epoch_length = 0.5  # 500ms for pieces\n",
    "        num_samples = int(sub_epoch_length * sfreq)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown epoch type: {epoch_type}\")\n",
    "\n",
    "    for sub_epoch in sub_epochs_data:\n",
    "        # Extract the data from the EpochsFIF object\n",
    "        sub_epoch_data = sub_epoch.get_data()\n",
    "\n",
    "        # Ensure nperseg does not exceed the number of samples in the sub-epoch\n",
    "        nperseg = min(sub_epoch_data.shape[2], num_samples)  # The third dimension contains the time samples\n",
    "\n",
    "        # Compute the PSD for the sub-epoch using Welch's method with the given nperseg\n",
    "        f, Pxx = welch(sub_epoch_data.squeeze(), sfreq, nperseg=nperseg)\n",
    "\n",
    "        # Calculate the spectral power in each band\n",
    "        band_powers = []\n",
    "        for band_name, (fmin, fmax) in bands.items():\n",
    "            band_freq_indices = (f >= fmin) & (f <= fmax)\n",
    "            if band_freq_indices.any():\n",
    "                band_power = Pxx[:, band_freq_indices].mean(axis=-1)\n",
    "                band_powers.append(band_power)\n",
    "            else:\n",
    "                band_powers.append(np.nan)  # Handle empty band\n",
    "\n",
    "        band_powers = np.hstack(band_powers) if band_powers else np.array([np.nan, np.nan, np.nan])\n",
    "        spectral_features.append(band_powers)\n",
    "\n",
    "        # Calculate Pearson correlation coefficient between pairs of channels for the sub-epoch\n",
    "        pcc = np.corrcoef(sub_epoch_data.squeeze(), rowvar=False)  # Use the numpy array here\n",
    "        pcc = pcc[np.triu_indices_from(pcc, k=1)]  # Take the upper triangle of the matrix, excluding the diagonal\n",
    "        pcc_features.extend(pcc)\n",
    "\n",
    "    spectral_features = np.vstack(spectral_features)\n",
    "    num_sub_epochs = len(sub_epochs_data)\n",
    "    pcc_features = np.array(pcc_features).reshape(num_sub_epochs, -1)\n",
    "    features = np.hstack([spectral_features, pcc_features]) if pcc_features.size else spectral_features\n",
    "\n",
    "    # After computing features, handle NaN values\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "    return features_imputed\n",
    "\n",
    "# Define the rescaling function\n",
    "def rescale_to_range(data, new_min, new_max):\n",
    "    old_min, old_max = np.min(data), np.max(data)\n",
    "    return new_min + (data - old_min) * (new_max - new_min) / (old_max - old_min)\n",
    "\n",
    "def create_vivid_cmap(base_cmap_name='Spectral', num_colors=256):\n",
    "    base_cmap = plt.cm.get_cmap(base_cmap_name)\n",
    "    base_colors = base_cmap(np.linspace(0, 1, num_colors))\n",
    "    colors_hsv = mcolors.rgb_to_hsv(base_colors[:, :3])\n",
    "    colors_hsv[:, 1] = 1.0  # max saturation\n",
    "    colors_hsv[:, 2] = 1.0  # max brightness\n",
    "    colors_rgb = mcolors.hsv_to_rgb(colors_hsv)\n",
    "    return mcolors.ListedColormap(colors_rgb, name='vivid_' + base_cmap_name)\n",
    "\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a 2D colormap\n",
    "num_colors = 256  # Number of colors to use in each dimension\n",
    "cmap = create_vivid_cmap('Spectral', num_colors)\n",
    "\n",
    "# Read raw data only once for each subject\n",
    "raw_data = {}\n",
    "\n",
    "for subject, raw_file_path in raw_file_paths.items():\n",
    "    raw_data[subject] = mne.io.read_raw_edf(raw_file_path, preload=True)\n",
    "    # Rescale channels only once\n",
    "    for ch in ['ft_valance', 'ft_arousal']:\n",
    "        if ch in raw_data[subject].ch_names:\n",
    "            data = raw_data[subject].get_data(picks=ch)\n",
    "            rescaled_data = rescale_to_range(data, -5, 5)\n",
    "            raw_data[subject]._data[raw_data[subject].ch_names.index(ch), :] = rescaled_data\n",
    "\n",
    "# Now process each epoch\n",
    "for subject, epoch_paths in processed_epochs_paths.items():\n",
    "    for epoch_index, epoch_path in enumerate(epoch_paths):\n",
    "        epochs = mne.read_epochs(epoch_path, preload=True)\n",
    "        raw = raw_data[subject]  # Use the preloaded and rescaled raw data\n",
    "\n",
    "        sfreq = epochs.info['sfreq']  # Get the sampling frequency from the epochs\n",
    "\n",
    "        # Determine the type of epoch based on the file name\n",
    "        if \"musicalphrase\" in epoch_path:\n",
    "            epoch_type = 'musicalphrase'\n",
    "            umap_params = {'n_neighbors': 5, 'min_dist': 0.1, 'n_components': 2, 'random_state': 42, 'metric': 'manhattan'}\n",
    "        elif \"musicalpiece\" in epoch_path:\n",
    "            epoch_type = 'musicalpiece'\n",
    "            umap_params = {'n_neighbors': 5, 'min_dist': 0.1, 'n_components': 2, 'random_state': 42, 'metric': 'manhattan'}\n",
    "        else:\n",
    "            raise ValueError(\"Unknown epoch type in path: \" + epoch_path)\n",
    "\n",
    "        # Determine the type of epoch and extract the number\n",
    "        if \"musicalphrase\" in epoch_path:\n",
    "            epoch_type = 'musicalphrase'\n",
    "            match = re.search(r'musicalphrase_(\\d+)', epoch_path)\n",
    "        elif \"musicalpiece\" in epoch_path:\n",
    "            epoch_type = 'musicalpiece'\n",
    "            match = re.search(r'musicalpiece_(\\d+)', epoch_path)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown epoch type in path: \" + epoch_path)\n",
    "        \n",
    "        # Extract the number (x) from the match if it exists\n",
    "        number = match.group(1) if match else \"unknown\"\n",
    "\n",
    "\n",
    "        # Use the determined epoch type to create sub-epochs\n",
    "        sub_epochs_data = create_sub_epochs(epochs, epoch_type=epoch_type)\n",
    "\n",
    "        # Extract valence and arousal data for each sub-epoch   \n",
    "        valance_arousal = []\n",
    "        for sub_epoch in sub_epochs_data:\n",
    "            valence_data, arousal_data = extract_valence_arousal_for_epoch(sub_epoch, raw)\n",
    "            valance_arousal.append(np.hstack((valence_data.mean(), arousal_data.mean())))\n",
    "        valance_arousal = np.array(valance_arousal)\n",
    "\n",
    "        # Extract features from the sub-epochs\n",
    "        features = extract_features(sub_epochs_data, sfreq, epoch_type)\n",
    "\n",
    "        # Check if features were extracted\n",
    "        if features is None or len(features) == 0:\n",
    "            print(f\"Subject {subject} Epoch {epoch_index+1} has no valid features. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Handle NaNs before scaling\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "        # Proceed with scaling and UMAP if features are present\n",
    "        features_scaled = scaler.fit_transform(features_imputed)\n",
    "\n",
    "        # Apply UMAP with the specific parameters for each epoch type\n",
    "        umap = UMAP(**umap_params)\n",
    "        embedding = umap.fit_transform(features_scaled)\n",
    "\n",
    "\n",
    "        # Before computing Spearman correlation, check for constant arrays\n",
    "        if np.std(umap_distances.ravel()) == 0 or np.std(valence_arousal_distances.ravel()) == 0:\n",
    "            # Handle the case where there's no variation in distances\n",
    "            # For example:\n",
    "            correlation = np.nan\n",
    "            p_value = np.nan\n",
    "        else:\n",
    "            correlation, p_value = spearmanr(umap_distances.ravel(), valence_arousal_distances.ravel())\n",
    "        # Compute Spearman correlation between UMAP and valence/arousal distances\n",
    "        umap_distances = squareform(pdist(embedding, 'euclidean'))\n",
    "        valence_arousal_distances = squareform(pdist(valance_arousal, 'euclidean'))\n",
    "        correlation, p_value = spearmanr(umap_distances.ravel(), valence_arousal_distances.ravel())\n",
    "        print(f\"Spearman correlation between UMAP distances and valence/arousal distances: {correlation} (p-value: {p_value})\")\n",
    "        \n",
    "        # Print shapes of the arrays to debug\n",
    "        print(f\"Subject {subject} Epoch {epoch_index+1}\")\n",
    "        print(\"embedding.shape:\", embedding.shape)\n",
    "        print(\"valance_arousal.shape:\", valance_arousal.shape)\n",
    "        \n",
    "        # Before normalization, check if the peak-to-peak value is zero and handle it\n",
    "        if np.ptp(valance_arousal[:, 0]) == 0 or np.ptp(valance_arousal[:, 1]) == 0:\n",
    "            # Handle the case where there's no variation in the valence or arousal\n",
    "            # Maybe set normalized values to zero or skip this epoch\n",
    "            # For example:\n",
    "            valence_normalized = np.zeros_like(valance_arousal[:, 0])\n",
    "            arousal_normalized = np.zeros_like(valance_arousal[:, 1])\n",
    "        else:\n",
    "            valence_normalized = (valance_arousal[:, 0] - np.min(valance_arousal[:, 0])) / np.ptp(valance_arousal[:, 0])\n",
    "            arousal_normalized = (valance_arousal[:, 1] - np.min(valance_arousal[:, 1])) / np.ptp(valance_arousal[:, 1])    \n",
    "\n",
    "        # Compute a color index for each point\n",
    "        valence_colors = np.int_(valence_normalized * (num_colors - 1))\n",
    "        arousal_colors = np.int_(arousal_normalized * (num_colors - 1))\n",
    "        colors = valence_colors + arousal_colors * num_colors\n",
    "\n",
    "        # Create a figure and a set of subplots\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "        # Plot UMAP embedding\n",
    "        scatter = ax.scatter(embedding[:, 0], embedding[:, 1], c=colors, cmap=cmap, s=5)\n",
    "\n",
    "        # Add colorbar using the computed 2D color mapping\n",
    "        norm = plt.Normalize(vmin=0, vmax=num_colors**2 - 1)\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = fig.colorbar(sm, ax=ax, orientation='horizontal')\n",
    "        cbar.set_label('Valence and Arousal')\n",
    "\n",
    "        # Set the title and labels with the new naming convention\n",
    "        ax.set_title(f'UMAP of Subject {subject} {epoch_type} {number} with Valence and Arousal Overlays')\n",
    "\n",
    "        # Remove the axes tick marks and labels\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# section 7: Final parameters used in the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20:04 version, update on the color spectrum but still keep previous results for comparing parameters\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "from mne import Epochs, find_events\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.colors as mcolors\n",
    "import re\n",
    "\n",
    "# Define paths to the processed epochs and the raw EEG files\n",
    "processed_epochs_paths = {\n",
    "    '02': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_2-epo.fif',\n",
    "    ],\n",
    "    '04': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '05': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '10': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '17': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '19': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '21': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "}\n",
    "\n",
    "raw_file_paths = {\n",
    "    '02': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-02\\\\eeg\\\\sub-02_task-classicalMusic_eeg.edf',\n",
    "    '04': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-04\\\\eeg\\\\sub-04_task-classicalMusic_eeg.edf',\n",
    "    '05': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-05\\\\eeg\\\\sub-05_task-classicalMusic_eeg.edf',\n",
    "    '10': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-10\\\\eeg\\\\sub-10_task-classicalMusic_eeg.edf',\n",
    "    '17': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-17\\\\eeg\\\\sub-17_task-classicalMusic_eeg.edf',\n",
    "    '19': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-19\\\\eeg\\\\sub-19_task-classicalMusic_eeg.edf',\n",
    "    '21': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-21\\\\eeg\\\\sub-21_task-classicalMusic_eeg.edf'\n",
    "}\n",
    "\n",
    "def create_sub_epochs(epochs, epoch_type):\n",
    "    sub_epochs_data = []\n",
    "    sfreq = epochs.info['sfreq']  # Sampling frequency\n",
    "    \n",
    "    if epoch_type == 'musicalphrase':\n",
    "        sub_epoch_length = 0.1  # 100ms for phrases\n",
    "    elif epoch_type == 'musicalpiece':\n",
    "        sub_epoch_length = 0.5 # 500ms for pieces\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown epoch type: {epoch_type}\")\n",
    "\n",
    "    # Calculate the number of samples for the given sub_epoch_length\n",
    "    sub_epoch_samples = int(sub_epoch_length * sfreq)\n",
    "\n",
    "    # Create sub-epochs\n",
    "    for start_time in np.arange(0, epochs.tmax, sub_epoch_length):\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = start_idx + sub_epoch_samples\n",
    "        if end_idx > len(epochs.times):  # Ensure we don't go past the end\n",
    "            break\n",
    "\n",
    "        # Ensure indices are integers and correct slicing\n",
    "        start_idx = int(start_idx)\n",
    "        end_idx = int(end_idx)\n",
    "        # Append sub-epoch data\n",
    "        sub_epochs_data.append(epochs.copy().crop(tmin=epochs.times[start_idx], tmax=epochs.times[end_idx-1], include_tmax=True))\n",
    "    \n",
    "    return sub_epochs_data\n",
    "\n",
    "def extract_valance_arousal_for_epoch(epoch, raw, valence_channel='ft_valance', arousal_channel='ft_arousal'):\n",
    "    \"\"\"\n",
    "    Extracts valence and arousal data for a given epoch from the raw EDF file.\n",
    "    \n",
    "    :param epoch: The epoch for which to extract valence and arousal\n",
    "    :param raw: The raw EDF data containing valence and arousal channels\n",
    "    :param valence_channel: The name of the valence channel\n",
    "    :param arousal_channel: The name of the arousal channel\n",
    "    :return: A tuple containing the valence and arousal data arrays\n",
    "    \"\"\"\n",
    "    # Get the start and end times of the epoch\n",
    "    start, end = epoch.times[0], epoch.times[-1]\n",
    "    start_sample, end_sample = int(start * raw.info['sfreq']), int(end * raw.info['sfreq'])\n",
    "    \n",
    "    # Extract valence and arousal data for the duration of the epoch\n",
    "    valence_data = raw.copy().pick_channels([valence_channel]).get_data(start=start_sample, stop=end_sample)\n",
    "    arousal_data = raw.copy().pick_channels([arousal_channel]).get_data(start=start_sample, stop=end_sample)\n",
    "    \n",
    "    return valence_data, arousal_data\n",
    "\n",
    "\n",
    "def extract_features(sub_epochs_data, sfreq, epoch_type):\n",
    "    features = []\n",
    "    # Define the frequency bands\n",
    "    bands = {'delta': (0.5, 4), 'theta': (4, 8), 'alpha': (8, 13)}\n",
    "    spectral_features = []\n",
    "    pcc_features = []\n",
    "\n",
    "    # Calculate the number of samples for the given sub_epoch lengths based on the sampling frequency\n",
    "    if epoch_type == 'musicalphrase':\n",
    "        sub_epoch_length = 0.1  # 100ms for phrases\n",
    "        num_samples = int(sub_epoch_length * sfreq)\n",
    "    elif epoch_type == 'musicalpiece':\n",
    "        sub_epoch_length = 0.5  # 500ms for pieces\n",
    "        num_samples = int(sub_epoch_length * sfreq)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown epoch type: {epoch_type}\")\n",
    "\n",
    "    for sub_epoch in sub_epochs_data:\n",
    "        # Extract the data from the EpochsFIF object\n",
    "        sub_epoch_data = sub_epoch.get_data()\n",
    "\n",
    "        # Ensure nperseg does not exceed the number of samples in the sub-epoch\n",
    "        nperseg = min(sub_epoch_data.shape[2], num_samples)  # The third dimension contains the time samples\n",
    "\n",
    "        # Compute the PSD for the sub-epoch using Welch's method with the given nperseg\n",
    "        f, Pxx = welch(sub_epoch_data.squeeze(), sfreq, nperseg=nperseg)\n",
    "\n",
    "        # Calculate the spectral power in each band\n",
    "        band_powers = []\n",
    "        for band_name, (fmin, fmax) in bands.items():\n",
    "            band_freq_indices = (f >= fmin) & (f <= fmax)\n",
    "            if band_freq_indices.any():\n",
    "                band_power = Pxx[:, band_freq_indices].mean(axis=-1)\n",
    "                band_powers.append(band_power)\n",
    "            else:\n",
    "                band_powers.append(np.nan)  # Handle empty band\n",
    "\n",
    "        band_powers = np.hstack(band_powers) if band_powers else np.array([np.nan, np.nan, np.nan])\n",
    "        spectral_features.append(band_powers)\n",
    "\n",
    "        # Calculate Pearson correlation coefficient between pairs of channels for the sub-epoch\n",
    "        pcc = np.corrcoef(sub_epoch_data.squeeze(), rowvar=False)  # Use the numpy array here\n",
    "        pcc = pcc[np.triu_indices_from(pcc, k=1)]  # Take the upper triangle of the matrix, excluding the diagonal\n",
    "        pcc_features.extend(pcc)\n",
    "\n",
    "    spectral_features = np.vstack(spectral_features)\n",
    "    num_sub_epochs = len(sub_epochs_data)\n",
    "    pcc_features = np.array(pcc_features).reshape(num_sub_epochs, -1)\n",
    "    features = np.hstack([spectral_features, pcc_features]) if pcc_features.size else spectral_features\n",
    "\n",
    "    # After computing features, handle NaN values\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "    return features_imputed\n",
    "\n",
    "# Define the rescaling function\n",
    "def rescale_to_range(data, new_min, new_max):\n",
    "    old_min, old_max = np.min(data), np.max(data)\n",
    "    return new_min + (data - old_min) * (new_max - new_min) / (old_max - old_min)\n",
    "\n",
    "def create_vivid_cmap(base_cmap_name='Spectral', num_colors=256):\n",
    "    base_cmap = plt.cm.get_cmap(base_cmap_name)\n",
    "    base_colors = base_cmap(np.linspace(0, 1, num_colors))\n",
    "    colors_hsv = mcolors.rgb_to_hsv(base_colors[:, :3])\n",
    "    colors_hsv[:, 1] = 1.0  # max saturation\n",
    "    colors_hsv[:, 2] = 1.0  # max brightness\n",
    "    colors_rgb = mcolors.hsv_to_rgb(colors_hsv)\n",
    "    return mcolors.ListedColormap(colors_rgb, name='vivid_' + base_cmap_name)\n",
    "\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a 2D colormap\n",
    "num_colors = 256  # Number of colors to use in each dimension\n",
    "cmap = create_vivid_cmap('Spectral', num_colors)\n",
    "\n",
    "# Read raw data only once for each subject\n",
    "raw_data = {}\n",
    "\n",
    "for subject, raw_file_path in raw_file_paths.items():\n",
    "    raw_data[subject] = mne.io.read_raw_edf(raw_file_path, preload=True)\n",
    "    # Rescale channels only once\n",
    "    for ch in ['ft_valance', 'ft_arousal']:\n",
    "        if ch in raw_data[subject].ch_names:\n",
    "            data = raw_data[subject].get_data(picks=ch)\n",
    "            rescaled_data = rescale_to_range(data, -5, 5)\n",
    "            raw_data[subject]._data[raw_data[subject].ch_names.index(ch), :] = rescaled_data\n",
    "\n",
    "# Now process each epoch\n",
    "for subject, epoch_paths in processed_epochs_paths.items():\n",
    "    for epoch_index, epoch_path in enumerate(epoch_paths):\n",
    "        epochs = mne.read_epochs(epoch_path, preload=True)\n",
    "        raw = raw_data[subject]  # Use the preloaded and rescaled raw data\n",
    "\n",
    "        sfreq = epochs.info['sfreq']  # Get the sampling frequency from the epochs\n",
    "\n",
    "        # Determine the type of epoch based on the file name\n",
    "        if \"musicalphrase\" in epoch_path:\n",
    "            epoch_type = 'musicalphrase'\n",
    "            umap_params = {'n_neighbors': 5, 'min_dist': 0.1, 'n_components': 2, 'random_state': 42}\n",
    "        elif \"musicalpiece\" in epoch_path:\n",
    "            epoch_type = 'musicalpiece'\n",
    "            umap_params = {'n_neighbors': 5, 'min_dist': 0.1, 'n_components': 2, 'random_state': 42}\n",
    "        else:\n",
    "            raise ValueError(\"Unknown epoch type in path: \" + epoch_path)\n",
    "\n",
    "        # Determine the type of epoch and extract the number\n",
    "        if \"musicalphrase\" in epoch_path:\n",
    "            epoch_type = 'musicalphrase'\n",
    "            match = re.search(r'musicalphrase_(\\d+)', epoch_path)\n",
    "        elif \"musicalpiece\" in epoch_path:\n",
    "            epoch_type = 'musicalpiece'\n",
    "            match = re.search(r'musicalpiece_(\\d+)', epoch_path)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown epoch type in path: \" + epoch_path)\n",
    "        \n",
    "        # Extract the number (x) from the match if it exists\n",
    "        number = match.group(1) if match else \"unknown\"\n",
    "\n",
    "\n",
    "        # Use the determined epoch type to create sub-epochs\n",
    "        sub_epochs_data = create_sub_epochs(epochs, epoch_type=epoch_type)\n",
    "\n",
    "        # Extract valence and arousal data for each sub-epoch   \n",
    "        valance_arousal = []\n",
    "        for sub_epoch in sub_epochs_data:\n",
    "            valence_data, arousal_data = extract_valence_arousal_for_epoch(sub_epoch, raw)\n",
    "            valance_arousal.append(np.hstack((valence_data.mean(), arousal_data.mean())))\n",
    "        valance_arousal = np.array(valance_arousal)\n",
    "\n",
    "        # Extract features from the sub-epochs\n",
    "        features = extract_features(sub_epochs_data, sfreq, epoch_type)\n",
    "\n",
    "        # Check if features were extracted\n",
    "        if features is None or len(features) == 0:\n",
    "            print(f\"Subject {subject} Epoch {epoch_index+1} has no valid features. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Handle NaNs before scaling\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "        # Proceed with scaling and UMAP if features are present\n",
    "        features_scaled = scaler.fit_transform(features_imputed)\n",
    "\n",
    "        # Apply UMAP with the specific parameters for each epoch type\n",
    "        umap = UMAP(**umap_params)\n",
    "        embedding = umap.fit_transform(features_scaled)\n",
    "\n",
    "\n",
    "        # Before computing Spearman correlation, check for constant arrays\n",
    "        if np.std(umap_distances.ravel()) == 0 or np.std(valence_arousal_distances.ravel()) == 0:\n",
    "            # Handle the case where there's no variation in distances\n",
    "            # For example:\n",
    "            correlation = np.nan\n",
    "            p_value = np.nan\n",
    "        else:\n",
    "            correlation, p_value = spearmanr(umap_distances.ravel(), valence_arousal_distances.ravel())\n",
    "        # Compute Spearman correlation between UMAP and valence/arousal distances\n",
    "        umap_distances = squareform(pdist(embedding, 'euclidean'))\n",
    "        valence_arousal_distances = squareform(pdist(valance_arousal, 'euclidean'))\n",
    "        correlation, p_value = spearmanr(umap_distances.ravel(), valence_arousal_distances.ravel())\n",
    "        print(f\"Spearman correlation between UMAP distances and valence/arousal distances: {correlation} (p-value: {p_value})\")\n",
    "        \n",
    "        # Print shapes of the arrays to debug\n",
    "        print(f\"Subject {subject} Epoch {epoch_index+1}\")\n",
    "        print(\"embedding.shape:\", embedding.shape)\n",
    "        print(\"valance_arousal.shape:\", valance_arousal.shape)\n",
    "        \n",
    "        # Before normalization, check if the peak-to-peak value is zero and handle it\n",
    "        if np.ptp(valance_arousal[:, 0]) == 0 or np.ptp(valance_arousal[:, 1]) == 0:\n",
    "            # Handle the case where there's no variation in the valence or arousal\n",
    "            # Maybe set normalized values to zero or skip this epoch\n",
    "            # For example:\n",
    "            valence_normalized = np.zeros_like(valance_arousal[:, 0])\n",
    "            arousal_normalized = np.zeros_like(valance_arousal[:, 1])\n",
    "        else:\n",
    "            valence_normalized = (valance_arousal[:, 0] - np.min(valance_arousal[:, 0])) / np.ptp(valance_arousal[:, 0])\n",
    "            arousal_normalized = (valance_arousal[:, 1] - np.min(valance_arousal[:, 1])) / np.ptp(valance_arousal[:, 1])    \n",
    "\n",
    "        # Compute a color index for each point\n",
    "        valence_colors = np.int_(valence_normalized * (num_colors - 1))\n",
    "        arousal_colors = np.int_(arousal_normalized * (num_colors - 1))\n",
    "        colors = valence_colors + arousal_colors * num_colors\n",
    "\n",
    "        # Create a figure and a set of subplots\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "        # Plot UMAP embedding\n",
    "        scatter = ax.scatter(embedding[:, 0], embedding[:, 1], c=colors, cmap=cmap, s=5)\n",
    "\n",
    "        # Add colorbar using the computed 2D color mapping\n",
    "        norm = plt.Normalize(vmin=0, vmax=num_colors**2 - 1)\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = fig.colorbar(sm, ax=ax, orientation='horizontal')\n",
    "        cbar.set_label('Valence and Arousal')\n",
    "\n",
    "        # Set the title and labels with the new naming convention\n",
    "        ax.set_title(f'UMAP of Subject {subject} {epoch_type} {number} with Valence and Arousal Overlays')\n",
    "\n",
    "        # Remove the axes tick marks and labels\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from mne import Epochs, find_events\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Define paths to the processed epochs and the raw EEG files\n",
    "processed_epochs_paths = {\n",
    "    '02': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_2-epo.fif',\n",
    "    ],\n",
    "    '04': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '05': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '10': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '17': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '19': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '21': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "}\n",
    "\n",
    "raw_file_paths = {\n",
    "    '02': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-02\\\\eeg\\\\sub-02_task-classicalMusic_eeg.edf',\n",
    "    '04': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-04\\\\eeg\\\\sub-04_task-classicalMusic_eeg.edf',\n",
    "    '05': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-05\\\\eeg\\\\sub-05_task-classicalMusic_eeg.edf',\n",
    "    '10': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-10\\\\eeg\\\\sub-10_task-classicalMusic_eeg.edf',\n",
    "    '17': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-17\\\\eeg\\\\sub-17_task-classicalMusic_eeg.edf',\n",
    "    '19': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-19\\\\eeg\\\\sub-19_task-classicalMusic_eeg.edf',\n",
    "    '21': 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-21\\\\eeg\\\\sub-21_task-classicalMusic_eeg.edf'\n",
    "}\n",
    "\n",
    "def create_sub_epochs(epochs, epoch_type):\n",
    "    sub_epochs_data = []\n",
    "    sfreq = epochs.info['sfreq']  # Sampling frequency\n",
    "    \n",
    "    if epoch_type == 'musicalphrase':\n",
    "        sub_epoch_length = 0.500  # 1s for phrases\n",
    "    elif epoch_type == 'musicalpiece':\n",
    "        sub_epoch_length = 1 # 5s for pieces\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown epoch type: {epoch_type}\")\n",
    "\n",
    "    # Calculate the number of samples for the given sub_epoch_length\n",
    "    sub_epoch_samples = int(sub_epoch_length * sfreq)\n",
    "\n",
    "    # Create sub-epochs\n",
    "    for start_time in np.arange(0, epochs.tmax, sub_epoch_length):\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = start_idx + sub_epoch_samples\n",
    "        if end_idx > len(epochs.times):  # Ensure we don't go past the end\n",
    "            break\n",
    "\n",
    "        # Ensure indices are integers and correct slicing\n",
    "        start_idx = int(start_idx)\n",
    "        end_idx = int(end_idx)\n",
    "        # Append sub-epoch data\n",
    "        sub_epochs_data.append(epochs.copy().crop(tmin=epochs.times[start_idx], tmax=epochs.times[end_idx-1], include_tmax=True))\n",
    "    \n",
    "    return sub_epochs_data\n",
    "\n",
    "def extract_valance_arousal_for_epoch(epoch, raw, valence_channel='ft_valance', arousal_channel='ft_arousal'):\n",
    "    \"\"\"\n",
    "    Extracts valence and arousal data for a given epoch from the raw EDF file.\n",
    "    \n",
    "    :param epoch: The epoch for which to extract valence and arousal\n",
    "    :param raw: The raw EDF data containing valence and arousal channels\n",
    "    :param valence_channel: The name of the valence channel\n",
    "    :param arousal_channel: The name of the arousal channel\n",
    "    :return: A tuple containing the valence and arousal data arrays\n",
    "    \"\"\"\n",
    "    # Get the start and end times of the epoch\n",
    "    start, end = epoch.times[0], epoch.times[-1]\n",
    "    start_sample, end_sample = int(start * raw.info['sfreq']), int(end * raw.info['sfreq'])\n",
    "    \n",
    "    # Extract valence and arousal data for the duration of the epoch\n",
    "    valence_data = raw.copy().pick_channels([valence_channel]).get_data(start=start_sample, stop=end_sample)\n",
    "    arousal_data = raw.copy().pick_channels([arousal_channel]).get_data(start=start_sample, stop=end_sample)\n",
    "    \n",
    "    return valence_data, arousal_data\n",
    "\n",
    "\n",
    "def extract_features(sub_epochs_data, sfreq, epoch_type):\n",
    "    features = []\n",
    "    # Define the frequency bands\n",
    "    bands = {'delta': (0.5, 4), 'theta': (4, 8), 'alpha': (8, 13)}\n",
    "    spectral_features = []\n",
    "    pcc_features = []\n",
    "\n",
    "    # Calculate the number of samples for the given sub_epoch lengths based on the sampling frequency\n",
    "    if epoch_type == 'musicalphrase':\n",
    "        sub_epoch_length = 0.500  # 1s for phrases\n",
    "        num_samples = int(sub_epoch_length * sfreq)\n",
    "    elif epoch_type == 'musicalpiece':\n",
    "        sub_epoch_length = 1  # 5s for pieces\n",
    "        num_samples = int(sub_epoch_length * sfreq)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown epoch type: {epoch_type}\")\n",
    "\n",
    "    for sub_epoch in sub_epochs_data:\n",
    "        # Extract the data from the EpochsFIF object\n",
    "        sub_epoch_data = sub_epoch.get_data()\n",
    "\n",
    "        # Ensure nperseg does not exceed the number of samples in the sub-epoch\n",
    "        nperseg = min(sub_epoch_data.shape[2], num_samples)  # The third dimension contains the time samples\n",
    "\n",
    "        # Compute the PSD for the sub-epoch using Welch's method with the given nperseg\n",
    "        f, Pxx = welch(sub_epoch_data.squeeze(), sfreq, nperseg=nperseg)\n",
    "\n",
    "        # Calculate the spectral power in each band\n",
    "        band_powers = []\n",
    "        for band_name, (fmin, fmax) in bands.items():\n",
    "            band_freq_indices = (f >= fmin) & (f <= fmax)\n",
    "            if band_freq_indices.any():\n",
    "                band_power = Pxx[:, band_freq_indices].mean(axis=-1)\n",
    "                band_powers.append(band_power)\n",
    "            else:\n",
    "                band_powers.append(np.nan)  # Handle empty band\n",
    "\n",
    "        band_powers = np.hstack(band_powers) if band_powers else np.array([np.nan, np.nan, np.nan])\n",
    "        spectral_features.append(band_powers)\n",
    "\n",
    "        # Calculate Pearson correlation coefficient between pairs of channels for the sub-epoch\n",
    "        pcc = np.corrcoef(sub_epoch_data.squeeze(), rowvar=False)  # Use the numpy array here\n",
    "        pcc = pcc[np.triu_indices_from(pcc, k=1)]  # Take the upper triangle of the matrix, excluding the diagonal\n",
    "        pcc_features.extend(pcc)\n",
    "\n",
    "    spectral_features = np.vstack(spectral_features)\n",
    "    num_sub_epochs = len(sub_epochs_data)\n",
    "    pcc_features = np.array(pcc_features).reshape(num_sub_epochs, -1)\n",
    "    features = np.hstack([spectral_features, pcc_features]) if pcc_features.size else spectral_features\n",
    "\n",
    "    # After computing features, handle NaN values\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "    return features_imputed\n",
    "\n",
    "# Define the rescaling function\n",
    "def rescale_to_range(data, new_min, new_max):\n",
    "    old_min, old_max = np.min(data), np.max(data)\n",
    "    return new_min + (data - old_min) * (new_max - new_min) / (old_max - old_min)\n",
    "\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a 2D colormap\n",
    "num_colors = 256  # Number of colors to use in each dimension\n",
    "cmap = plt.get_cmap('Spectral', num_colors**2)  # Use a colormap with enough colors\n",
    "\n",
    "# Read raw data only once for each subject\n",
    "raw_data = {}\n",
    "\n",
    "for subject, raw_file_path in raw_file_paths.items():\n",
    "    raw_data[subject] = mne.io.read_raw_edf(raw_file_path, preload=True)\n",
    "    # Rescale channels only once\n",
    "    for ch in ['ft_valance', 'ft_arousal']:\n",
    "        if ch in raw_data[subject].ch_names:\n",
    "            data = raw_data[subject].get_data(picks=ch)\n",
    "            rescaled_data = rescale_to_range(data, -5, 5)\n",
    "            raw_data[subject]._data[raw_data[subject].ch_names.index(ch), :] = rescaled_data\n",
    "\n",
    "# Now process each epoch\n",
    "for subject, epoch_paths in processed_epochs_paths.items():\n",
    "    for epoch_index, epoch_path in enumerate(epoch_paths):\n",
    "        epochs = mne.read_epochs(epoch_path, preload=True)\n",
    "        raw = raw_data[subject]  # Use the preloaded and rescaled raw data\n",
    "\n",
    "        sfreq = epochs.info['sfreq']  # Get the sampling frequency from the epochs\n",
    "\n",
    "        # Determine the type of epoch based on the file name\n",
    "        if \"musicalphrase\" in epoch_path:\n",
    "            epoch_type = 'musicalphrase'\n",
    "            umap_params = {'n_neighbors': 5, 'min_dist': 0.1, 'n_components': 2, 'random_state': 42}\n",
    "        elif \"musicalpiece\" in epoch_path:\n",
    "            epoch_type = 'musicalpiece'\n",
    "            umap_params = {'n_neighbors': 5, 'min_dist': 0.1, 'n_components': 2, 'random_state': 42}\n",
    "        else:\n",
    "            raise ValueError(\"Unknown epoch type in path: \" + epoch_path)\n",
    "\n",
    "        # Use the determined epoch type to create sub-epochs\n",
    "        sub_epochs_data = create_sub_epochs(epochs, epoch_type=epoch_type)\n",
    "\n",
    "        # Extract valence and arousal data for each sub-epoch   \n",
    "        valance_arousal = []\n",
    "        for sub_epoch in sub_epochs_data:\n",
    "            valence_data, arousal_data = extract_valence_arousal_for_epoch(sub_epoch, raw)\n",
    "            valance_arousal.append(np.hstack((valence_data.mean(), arousal_data.mean())))\n",
    "        valance_arousal = np.array(valance_arousal)\n",
    "\n",
    "        # Extract features from the sub-epochs\n",
    "        features = extract_features(sub_epochs_data, sfreq, epoch_type)\n",
    "\n",
    "        # Check if features were extracted\n",
    "        if features is None or len(features) == 0:\n",
    "            print(f\"Subject {subject} Epoch {epoch_index+1} has no valid features. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Handle NaNs before scaling\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "        # Proceed with scaling and UMAP if features are present\n",
    "        features_scaled = scaler.fit_transform(features_imputed)\n",
    "\n",
    "        # Apply UMAP with the specific parameters for each epoch type\n",
    "        umap = UMAP(**umap_params)\n",
    "        embedding = umap.fit_transform(features_scaled)\n",
    "\n",
    "        # Compute Spearman correlation between UMAP and valence/arousal distances\n",
    "        umap_distances = squareform(pdist(embedding, 'euclidean'))\n",
    "        valence_arousal_distances = squareform(pdist(valance_arousal, 'euclidean'))\n",
    "        correlation, p_value = spearmanr(umap_distances.ravel(), valence_arousal_distances.ravel())\n",
    "        print(f\"Spearman correlation between UMAP distances and valence/arousal distances: {correlation} (p-value: {p_value})\")\n",
    "        \n",
    "        # Print shapes of the arrays to debug\n",
    "        print(f\"Subject {subject} Epoch {epoch_index+1}\")\n",
    "        print(\"embedding.shape:\", embedding.shape)\n",
    "        print(\"valance_arousal.shape:\", valance_arousal.shape)\n",
    "        \n",
    "        # Normalize valence and arousal\n",
    "        valence_normalized = (valance_arousal[:, 0] - np.min(valance_arousal[:, 0])) / np.ptp(valance_arousal[:, 0])\n",
    "        arousal_normalized = (valance_arousal[:, 1] - np.min(valance_arousal[:, 1])) / np.ptp(valance_arousal[:, 1])\n",
    "\n",
    "        # Compute a color index for each point\n",
    "        valence_colors = np.int_(valence_normalized * (num_colors - 1))\n",
    "        arousal_colors = np.int_(arousal_normalized * (num_colors - 1))\n",
    "        colors = valence_colors + arousal_colors * num_colors\n",
    "\n",
    "        # Create a figure and a set of subplots\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "        # Plot UMAP embedding\n",
    "        scatter = ax.scatter(embedding[:, 0], embedding[:, 1], c=colors, cmap=cmap, s=5)\n",
    "\n",
    "        # Add colorbar using the computed 2D color mapping\n",
    "        norm = plt.Normalize(vmin=0, vmax=num_colors**2 - 1)\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = fig.colorbar(sm, ax=ax, orientation='horizontal')\n",
    "        cbar.set_label('Valence and Arousal')\n",
    "\n",
    "        ax.set_title(f'UMAP of Subject {subject} Epoch {epoch_index+1} with Valence and Arousal Overlays')\n",
    "        ax.set_xlabel('UMAP Component 1')\n",
    "        ax.set_ylabel('UMAP Component 2')\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from mne import Epochs, find_events\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "# Define paths to the processed epochs and the raw EEG files\n",
    "processed_epochs_paths = {\n",
    "    '02': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_2-epo.fif',\n",
    "    ],\n",
    "    '04': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '05': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '10': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '17': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '19': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '21': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "}\n",
    "\n",
    "def create_sub_epochs(epochs, epoch_type):\n",
    "    sub_epochs_data = []\n",
    "    sfreq = epochs.info['sfreq']  # Sampling frequency\n",
    "    \n",
    "    if epoch_type == 'musicalphrase':\n",
    "        sub_epoch_length = 0.1  # 100 ms for phrases\n",
    "    elif epoch_type == 'musicalpiece':\n",
    "        sub_epoch_length = 0.5  # 1 second for pieces\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown epoch type: {epoch_type}\")\n",
    "\n",
    "    # Calculate the number of samples for the given sub_epoch_length\n",
    "    sub_epoch_samples = int(sub_epoch_length * sfreq)\n",
    "\n",
    "    # Create sub-epochs\n",
    "    for start_time in np.arange(0, epochs.tmax, sub_epoch_length):\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = start_idx + sub_epoch_samples\n",
    "        if end_idx > len(epochs.times):  # Ensure we don't go past the end\n",
    "            break\n",
    "\n",
    "        # Ensure indices are integers and correct slicing\n",
    "        start_idx = int(start_idx)\n",
    "        end_idx = int(end_idx)\n",
    "        # Append sub-epoch data\n",
    "        sub_epochs_data.append(epochs.copy().crop(tmin=epochs.times[start_idx], tmax=epochs.times[end_idx-1], include_tmax=True))\n",
    "    \n",
    "    return sub_epochs_data\n",
    "\n",
    "\n",
    "def extract_features(sub_epochs_data, sfreq, epoch_type):\n",
    "    features = []\n",
    "    # Define the frequency bands\n",
    "    bands = {'delta': (0.5, 4), 'theta': (4, 8), 'alpha': (8, 13)}\n",
    "    spectral_features = []\n",
    "    pcc_features = []\n",
    "\n",
    "    # Calculate the number of samples for the given sub_epoch lengths based on the sampling frequency\n",
    "    if epoch_type == 'musicalphrase':\n",
    "        sub_epoch_length = 0.1  # 100 ms for phrases\n",
    "        num_samples = int(sub_epoch_length * sfreq)\n",
    "    elif epoch_type == 'musicalpiece':\n",
    "        sub_epoch_length = 1.0  # 1 second for pieces\n",
    "        num_samples = int(sub_epoch_length * sfreq)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown epoch type: {epoch_type}\")\n",
    "\n",
    "    for sub_epoch in sub_epochs_data:\n",
    "        # Extract the data from the EpochsFIF object\n",
    "        sub_epoch_data = sub_epoch.get_data()\n",
    "\n",
    "        # Ensure nperseg does not exceed the number of samples in the sub-epoch\n",
    "        nperseg = min(sub_epoch_data.shape[2], num_samples)  # The third dimension contains the time samples\n",
    "\n",
    "        # Compute the PSD for the sub-epoch using Welch's method with the given nperseg\n",
    "        f, Pxx = welch(sub_epoch_data.squeeze(), sfreq, nperseg=nperseg)\n",
    "\n",
    "        # Calculate the spectral power in each band\n",
    "        band_powers = []\n",
    "        for band_name, (fmin, fmax) in bands.items():\n",
    "            band_freq_indices = (f >= fmin) & (f <= fmax)\n",
    "            if band_freq_indices.any():\n",
    "                band_power = Pxx[:, band_freq_indices].mean(axis=-1)\n",
    "                band_powers.append(band_power)\n",
    "            else:\n",
    "                band_powers.append(np.nan)  # Handle empty band\n",
    "\n",
    "        band_powers = np.hstack(band_powers) if band_powers else np.array([np.nan, np.nan, np.nan])\n",
    "        spectral_features.append(band_powers)\n",
    "\n",
    "        # Calculate Pearson correlation coefficient between pairs of channels for the sub-epoch\n",
    "        pcc = np.corrcoef(sub_epoch_data.squeeze(), rowvar=False)  # Use the numpy array here\n",
    "        pcc = pcc[np.triu_indices_from(pcc, k=1)]  # Take the upper triangle of the matrix, excluding the diagonal\n",
    "        pcc_features.extend(pcc)\n",
    "\n",
    "    spectral_features = np.vstack(spectral_features)\n",
    "    num_sub_epochs = len(sub_epochs_data)\n",
    "    pcc_features = np.array(pcc_features).reshape(num_sub_epochs, -1)\n",
    "    features = np.hstack([spectral_features, pcc_features]) if pcc_features.size else spectral_features\n",
    "\n",
    "    # After computing features, handle NaN values\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "    return features_imputed\n",
    "\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Process each subject's epochs\n",
    "for subject, epoch_paths in processed_epochs_paths.items():\n",
    "    for epoch_index, epoch_path in enumerate(epoch_paths):\n",
    "        epochs = mne.read_epochs(epoch_path, preload=True)\n",
    "        sfreq = epochs.info['sfreq']  # Get the sampling frequency from the epochs\n",
    "\n",
    "        # Determine the type of epoch based on the file name\n",
    "        if \"musicalphrase\" in epoch_path:\n",
    "            epoch_type = 'musicalphrase'\n",
    "        elif \"musicalpiece\" in epoch_path:\n",
    "            epoch_type = 'musicalpiece'\n",
    "        else:\n",
    "            raise ValueError(\"Unknown epoch type in path: \" + epoch_path)\n",
    "\n",
    "        # Use the determined epoch type to create sub-epochs\n",
    "        sub_epochs_data = create_sub_epochs(epochs, epoch_type=epoch_type)\n",
    "\n",
    "        # Extract features from the sub-epochs\n",
    "        features = extract_features(sub_epochs_data, sfreq, epoch_type)\n",
    "\n",
    "        # Check if features were extracted\n",
    "        if features is None or len(features) == 0:\n",
    "            print(f\"Subject {subject} Epoch {epoch_index+1} has no valid features. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Handle NaNs before scaling\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "        # Proceed with scaling and UMAP if features are present\n",
    "        features_scaled = scaler.fit_transform(features_imputed)\n",
    "        umap = UMAP(n_neighbors=5, min_dist=0.5, spread=1.0, metric='manhattan')\n",
    "        embedding = umap.fit_transform(features_scaled)\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.scatter(embedding[:, 0], embedding[:, 1], s=5)\n",
    "        plt.title(f\"UMAP of Subject {subject} Epoch {epoch_index+1}\")\n",
    "        plt.xlabel('UMAP Component 1')\n",
    "        plt.ylabel('UMAP Component 2')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from mne import Epochs, find_events\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "# Define paths to the processed epochs and the raw EEG files\n",
    "processed_epochs_paths = {\n",
    "    '02': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_2-epo.fif',\n",
    "    ],\n",
    "    '04': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '05': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '10': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '17': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '19': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '21': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "}\n",
    "\n",
    "def create_sub_epochs(epochs, epoch_type):\n",
    "    sub_epochs_data = []\n",
    "    sfreq = epochs.info['sfreq']  # Sampling frequency\n",
    "    \n",
    "    if epoch_type == 'musicalphrase':\n",
    "        sub_epoch_length = 0.1  # 100 ms for phrases\n",
    "    elif epoch_type == 'musicalpiece':\n",
    "        sub_epoch_length = 0.5  # 1 second for pieces\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown epoch type: {epoch_type}\")\n",
    "\n",
    "    # Calculate the number of samples for the given sub_epoch_length\n",
    "    sub_epoch_samples = int(sub_epoch_length * sfreq)\n",
    "\n",
    "    # Create sub-epochs\n",
    "    for start_time in np.arange(0, epochs.tmax, sub_epoch_length):\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = start_idx + sub_epoch_samples\n",
    "        if end_idx > len(epochs.times):  # Ensure we don't go past the end\n",
    "            break\n",
    "\n",
    "        # Ensure indices are integers and correct slicing\n",
    "        start_idx = int(start_idx)\n",
    "        end_idx = int(end_idx)\n",
    "        # Append sub-epoch data\n",
    "        sub_epochs_data.append(epochs.copy().crop(tmin=epochs.times[start_idx], tmax=epochs.times[end_idx-1], include_tmax=True))\n",
    "    \n",
    "    return sub_epochs_data\n",
    "\n",
    "\n",
    "def extract_features(sub_epochs_data, sfreq, epoch_type):\n",
    "    features = []\n",
    "    # Define the frequency bands\n",
    "    bands = {'delta': (0.5, 4), 'theta': (4, 8), 'alpha': (8, 13)}\n",
    "    spectral_features = []\n",
    "    pcc_features = []\n",
    "\n",
    "    # Calculate the number of samples for the given sub_epoch lengths based on the sampling frequency\n",
    "    if epoch_type == 'musicalphrase':\n",
    "        sub_epoch_length = 0.1  # 100 ms for phrases\n",
    "        num_samples = int(sub_epoch_length * sfreq)\n",
    "    elif epoch_type == 'musicalpiece':\n",
    "        sub_epoch_length = 0.5  # 1 second for pieces\n",
    "        num_samples = int(sub_epoch_length * sfreq)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown epoch type: {epoch_type}\")\n",
    "\n",
    "    for sub_epoch in sub_epochs_data:\n",
    "        # Extract the data from the EpochsFIF object\n",
    "        sub_epoch_data = sub_epoch.get_data()\n",
    "\n",
    "        # Ensure nperseg does not exceed the number of samples in the sub-epoch\n",
    "        nperseg = min(sub_epoch_data.shape[2], num_samples)  # The third dimension contains the time samples\n",
    "\n",
    "        # Compute the PSD for the sub-epoch using Welch's method with the given nperseg\n",
    "        f, Pxx = welch(sub_epoch_data.squeeze(), sfreq, nperseg=nperseg)\n",
    "\n",
    "        # Calculate the spectral power in each band\n",
    "        band_powers = []\n",
    "        for band_name, (fmin, fmax) in bands.items():\n",
    "            band_freq_indices = (f >= fmin) & (f <= fmax)\n",
    "            if band_freq_indices.any():\n",
    "                band_power = Pxx[:, band_freq_indices].mean(axis=-1)\n",
    "                band_powers.append(band_power)\n",
    "            else:\n",
    "                band_powers.append(np.nan)  # Handle empty band\n",
    "\n",
    "        band_powers = np.hstack(band_powers) if band_powers else np.array([np.nan, np.nan, np.nan])\n",
    "        spectral_features.append(band_powers)\n",
    "\n",
    "        # Calculate Pearson correlation coefficient between pairs of channels for the sub-epoch\n",
    "        pcc = np.corrcoef(sub_epoch_data.squeeze(), rowvar=False)  # Use the numpy array here\n",
    "        pcc = pcc[np.triu_indices_from(pcc, k=1)]  # Take the upper triangle of the matrix, excluding the diagonal\n",
    "        pcc_features.extend(pcc)\n",
    "\n",
    "    spectral_features = np.vstack(spectral_features)\n",
    "    num_sub_epochs = len(sub_epochs_data)\n",
    "    pcc_features = np.array(pcc_features).reshape(num_sub_epochs, -1)\n",
    "    features = np.hstack([spectral_features, pcc_features]) if pcc_features.size else spectral_features\n",
    "\n",
    "    # After computing features, handle NaN values\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "    return features_imputed\n",
    "\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Process each subject's epochs\n",
    "for subject, epoch_paths in processed_epochs_paths.items():\n",
    "    for epoch_index, epoch_path in enumerate(epoch_paths):\n",
    "        epochs = mne.read_epochs(epoch_path, preload=True)\n",
    "        sfreq = epochs.info['sfreq']  # Get the sampling frequency from the epochs\n",
    "\n",
    "        # Determine the type of epoch based on the file name\n",
    "        if \"musicalphrase\" in epoch_path:\n",
    "            epoch_type = 'musicalphrase'\n",
    "        elif \"musicalpiece\" in epoch_path:\n",
    "            epoch_type = 'musicalpiece'\n",
    "        else:\n",
    "            raise ValueError(\"Unknown epoch type in path: \" + epoch_path)\n",
    "\n",
    "        # Use the determined epoch type to create sub-epochs\n",
    "        sub_epochs_data = create_sub_epochs(epochs, epoch_type=epoch_type)\n",
    "\n",
    "        # Extract features from the sub-epochs\n",
    "        features = extract_features(sub_epochs_data, sfreq, epoch_type)\n",
    "\n",
    "        # Check if features were extracted\n",
    "        if features is None or len(features) == 0:\n",
    "            print(f\"Subject {subject} Epoch {epoch_index+1} has no valid features. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Handle NaNs before scaling\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "        # Proceed with scaling and UMAP if features are present\n",
    "        features_scaled = scaler.fit_transform(features_imputed)\n",
    "        umap = UMAP(n_neighbors=5, min_dist=0.1, n_components=2, random_state=42)\n",
    "        embedding = umap.fit_transform(features_scaled)\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.scatter(embedding[:, 0], embedding[:, 1], s=5)\n",
    "        plt.title(f\"UMAP of Subject {subject} Epoch {epoch_index+1}\")\n",
    "        plt.xlabel('UMAP Component 1')\n",
    "        plt.ylabel('UMAP Component 2')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from mne import Epochs, find_events\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "# Define paths to the processed epochs and the raw EEG files\n",
    "processed_epochs_paths = {\n",
    "    '02': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\02\\\\02_musicalpiece_2-epo.fif',\n",
    "    ],\n",
    "    '04': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\04\\\\04_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '05': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\05\\\\05_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '10': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\10\\\\10_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '17': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\17\\\\17_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '19': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\19\\\\19_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "    '21': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalpieces_data\\\\21\\\\21_musicalpiece_3-epo.fif'\n",
    "    ],\n",
    "}\n",
    "\n",
    "def create_sub_epochs(epochs, epoch_type):\n",
    "    sub_epochs_data = []\n",
    "    sfreq = epochs.info['sfreq']  # Sampling frequency\n",
    "    \n",
    "    if epoch_type == 'musicalphrase':\n",
    "        sub_epoch_length = 0.1  # 100 ms for phrases\n",
    "    elif epoch_type == 'musicalpiece':\n",
    "        sub_epoch_length = 0.5  # 1 second for pieces\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown epoch type: {epoch_type}\")\n",
    "\n",
    "    # Calculate the number of samples for the given sub_epoch_length\n",
    "    sub_epoch_samples = int(sub_epoch_length * sfreq)\n",
    "\n",
    "    # Create sub-epochs\n",
    "    for start_time in np.arange(0, epochs.tmax, sub_epoch_length):\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = start_idx + sub_epoch_samples\n",
    "        if end_idx > len(epochs.times):  # Ensure we don't go past the end\n",
    "            break\n",
    "\n",
    "        # Ensure indices are integers and correct slicing\n",
    "        start_idx = int(start_idx)\n",
    "        end_idx = int(end_idx)\n",
    "        # Append sub-epoch data\n",
    "        sub_epochs_data.append(epochs.copy().crop(tmin=epochs.times[start_idx], tmax=epochs.times[end_idx-1], include_tmax=True))\n",
    "    \n",
    "    return sub_epochs_data\n",
    "\n",
    "\n",
    "def extract_features(sub_epochs_data, sfreq, epoch_type):\n",
    "    features = []\n",
    "    # Define the frequency bands\n",
    "    bands = {'delta': (0.5, 4), 'theta': (4, 8), 'alpha': (8, 13)}\n",
    "    spectral_features = []\n",
    "    pcc_features = []\n",
    "\n",
    "    # Calculate the number of samples for the given sub_epoch lengths based on the sampling frequency\n",
    "    if epoch_type == 'musicalphrase':\n",
    "        sub_epoch_length = 0.1  # 100 ms for phrases\n",
    "        num_samples = int(sub_epoch_length * sfreq)\n",
    "    elif epoch_type == 'musicalpiece':\n",
    "        sub_epoch_length = 1.0  # 1 second for pieces\n",
    "        num_samples = int(sub_epoch_length * sfreq)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown epoch type: {epoch_type}\")\n",
    "\n",
    "    for sub_epoch in sub_epochs_data:\n",
    "        # Extract the data from the EpochsFIF object\n",
    "        sub_epoch_data = sub_epoch.get_data()\n",
    "\n",
    "        # Ensure nperseg does not exceed the number of samples in the sub-epoch\n",
    "        nperseg = min(sub_epoch_data.shape[2], num_samples)  # The third dimension contains the time samples\n",
    "\n",
    "        # Compute the PSD for the sub-epoch using Welch's method with the given nperseg\n",
    "        f, Pxx = welch(sub_epoch_data.squeeze(), sfreq, nperseg=nperseg)\n",
    "\n",
    "        # Calculate the spectral power in each band\n",
    "        band_powers = []\n",
    "        for band_name, (fmin, fmax) in bands.items():\n",
    "            band_freq_indices = (f >= fmin) & (f <= fmax)\n",
    "            if band_freq_indices.any():\n",
    "                band_power = Pxx[:, band_freq_indices].mean(axis=-1)\n",
    "                band_powers.append(band_power)\n",
    "            else:\n",
    "                band_powers.append(np.nan)  # Handle empty band\n",
    "\n",
    "        band_powers = np.hstack(band_powers) if band_powers else np.array([np.nan, np.nan, np.nan])\n",
    "        spectral_features.append(band_powers)\n",
    "\n",
    "        # Calculate Pearson correlation coefficient between pairs of channels for the sub-epoch\n",
    "        pcc = np.corrcoef(sub_epoch_data.squeeze(), rowvar=False)  # Use the numpy array here\n",
    "        pcc = pcc[np.triu_indices_from(pcc, k=1)]  # Take the upper triangle of the matrix, excluding the diagonal\n",
    "        pcc_features.extend(pcc)\n",
    "\n",
    "    spectral_features = np.vstack(spectral_features)\n",
    "    num_sub_epochs = len(sub_epochs_data)\n",
    "    pcc_features = np.array(pcc_features).reshape(num_sub_epochs, -1)\n",
    "    features = np.hstack([spectral_features, pcc_features]) if pcc_features.size else spectral_features\n",
    "\n",
    "    # After computing features, handle NaN values\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "    return features_imputed\n",
    "\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Process each subject's epochs\n",
    "for subject, epoch_paths in processed_epochs_paths.items():\n",
    "    for epoch_index, epoch_path in enumerate(epoch_paths):\n",
    "        epochs = mne.read_epochs(epoch_path, preload=True)\n",
    "        sfreq = epochs.info['sfreq']  # Get the sampling frequency from the epochs\n",
    "\n",
    "        # Determine the type of epoch based on the file name\n",
    "        if \"musicalphrase\" in epoch_path:\n",
    "            epoch_type = 'musicalphrase'\n",
    "        elif \"musicalpiece\" in epoch_path:\n",
    "            epoch_type = 'musicalpiece'\n",
    "        else:\n",
    "            raise ValueError(\"Unknown epoch type in path: \" + epoch_path)\n",
    "\n",
    "        # Use the determined epoch type to create sub-epochs\n",
    "        sub_epochs_data = create_sub_epochs(epochs, epoch_type=epoch_type)\n",
    "\n",
    "        # Extract features from the sub-epochs\n",
    "        features = extract_features(sub_epochs_data, sfreq, epoch_type)\n",
    "\n",
    "        # Check if features were extracted\n",
    "        if features is None or len(features) == 0:\n",
    "            print(f\"Subject {subject} Epoch {epoch_index+1} has no valid features. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Handle NaNs before scaling\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "        # Proceed with scaling and UMAP if features are present\n",
    "        features_scaled = scaler.fit_transform(features_imputed)\n",
    "        umap = UMAP(n_neighbors=5, min_dist=0.1, n_components=2, random_state=42)\n",
    "        embedding = umap.fit_transform(features_scaled)\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.scatter(embedding[:, 0], embedding[:, 1], s=5)\n",
    "        plt.title(f\"UMAP of Subject {subject} Epoch {epoch_index+1}\")\n",
    "        plt.xlabel('UMAP Component 1')\n",
    "        plt.ylabel('UMAP Component 2')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import pearsonr\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths to the processed epochs and the raw EEG files\n",
    "processed_epochs_paths = {\n",
    "    '02': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\02\\\\02_musicalmoment_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\02\\\\02_musicalmoment_2-epo.fif',\n",
    "    ],\n",
    "    '04': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\04\\\\04_musicalmoment_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\04\\\\04_musicalmoment_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\04\\\\04_musicalmoment_3-epo.fif'\n",
    "    ],\n",
    "    '05': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\05\\\\05_musicalmoment_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\05\\\\05_musicalmoment_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\05\\\\05_musicalmoment_3-epo.fif'\n",
    "    ],\n",
    "    '10': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\10\\\\10_musicalmoment_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\10\\\\10_musicalmoment_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\10\\\\10_musicalmoment_3-epo.fif'\n",
    "    ],\n",
    "    '17': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\17\\\\17_musicalmoment_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\17\\\\17_musicalmoment_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\17\\\\17_musicalmoment_3-epo.fif'\n",
    "    ],\n",
    "    '19': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\19\\\\19_musicalmoment_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\19\\\\19_musicalmoment_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\19\\\\19_musicalmoment_3-epo.fif'\n",
    "    ],\n",
    "    '21': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\21\\\\21_musicalmoment_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\21\\\\21_musicalmoment_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\21\\\\21_musicalmoment_3-epo.fif'\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Function to extract features from epochs\n",
    "def extract_features(epochs):\n",
    "    features = []\n",
    "    \n",
    "    # Extract spectral power using the new compute_psd method\n",
    "    psd = epochs.compute_psd(fmin=0.5, fmax=47, method='welch')\n",
    "    psds, freqs = psd.get_data(return_freqs=True)\n",
    "    print(\"PSDs shape:\", psds.shape)  # Debugging line\n",
    "    print(\"Frequencies:\", freqs)  # Debugging line\n",
    "\n",
    "    # Define the frequency bands\n",
    "    bands = {'delta': (0.5, 4), 'theta': (4, 8), 'alpha': (8, 13)}\n",
    "\n",
    "    # Calculate the spectral power in each band\n",
    "    spectral_features = []\n",
    "    for band_name, (fmin, fmax) in bands.items():\n",
    "        psd_band = psds[:, :, (freqs >= fmin) & (freqs <= fmax)].mean(axis=-1)\n",
    "        print(f\"Band {band_name} feature shape:\", psd_band.shape)  # Debugging line\n",
    "        spectral_features.append(psd_band)\n",
    "    \n",
    "    spectral_features = np.hstack(spectral_features)\n",
    "    print(\"Spectral features shape:\", spectral_features.shape)  # Debugging line\n",
    "\n",
    "    # Calculate Pearson correlation coefficient between pairs of channels for each epoch\n",
    "    pcc_features = []\n",
    "    for epoch_data in epochs.get_data():\n",
    "        pcc, _ = pearsonr(epoch_data[0], epoch_data[1])\n",
    "        pcc_features.append(pcc)\n",
    "    \n",
    "    pcc_features = np.array(pcc_features).reshape(-1, 1)\n",
    "    print(\"PCC features shape:\", pcc_features.shape)  # Debugging line\n",
    "    print(\"PCC features:\", pcc_features)  # Debugging line\n",
    "\n",
    "    # Combine spectral and PCC features\n",
    "    features = np.hstack([spectral_features, pcc_features])\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Feature array placeholder\n",
    "all_features = []\n",
    "\n",
    "# Loop over each subject and each epoch path\n",
    "for subject, epoch_paths in processed_epochs_paths.items():\n",
    "    for epoch_index, epoch_path in enumerate(epoch_paths):\n",
    "        # Load the epochs\n",
    "        epochs = mne.read_epochs(epoch_path, preload=True)\n",
    "        \n",
    "        # Extract features\n",
    "        features = extract_features(epochs)\n",
    "        \n",
    "        # Scale the features for the current epoch        \n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "        # Initialize UMAP with desired parameters for the current epoch\n",
    "        umap = UMAP(n_neighbors=5, min_dist=0.5, n_components=2, random_state=42)\n",
    "        \n",
    "        # Fit UMAP to the scaled features for the current epoch\n",
    "        embedding = umap.fit_transform(features_scaled)\n",
    "        \n",
    "        # Now you can create a UMAP visualization for the current epoch\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.scatter(embedding[:, 0], embedding[:, 1], s=5)  # s is the size of points\n",
    "        plt.title(f\"UMAP of Subject {subject} Epoch {epoch_index+1}\")\n",
    "        plt.xlabel('UMAP Component 1')\n",
    "        plt.ylabel('UMAP Component 2')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define paths to the processed epochs and the raw EEG files\n",
    "processed_epochs_paths = {\n",
    "    '02': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\02\\\\02_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\02\\\\02_musicalmoment_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\02\\\\02_musicalmoment_2-epo.fif',\n",
    "    ],\n",
    "    '04': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\04\\\\04_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\04\\\\04_musicalmoment_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\04\\\\04_musicalmoment_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\04\\\\04_musicalmoment_3-epo.fif'\n",
    "    ],\n",
    "    '05': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\05\\\\05_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\05\\\\05_musicalmoment_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\05\\\\05_musicalmoment_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\05\\\\05_musicalmoment_3-epo.fif'\n",
    "    ],\n",
    "    '10': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\10\\\\10_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\10\\\\10_musicalmoment_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\10\\\\10_musicalmoment_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\10\\\\10_musicalmoment_3-epo.fif'\n",
    "    ],\n",
    "    '17': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\17\\\\17_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\17\\\\17_musicalmoment_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\17\\\\17_musicalmoment_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\17\\\\17_musicalmoment_3-epo.fif'\n",
    "    ],\n",
    "    '19': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\19\\\\19_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\19\\\\19_musicalmoment_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\19\\\\19_musicalmoment_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\19\\\\19_musicalmoment_3-epo.fif'\n",
    "    ],\n",
    "    '21': [\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalphrases_data\\\\21\\\\21_musicalphrase_3-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\21\\\\21_musicalmoment_1-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\21\\\\21_musicalmoment_2-epo.fif',\n",
    "        'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\musicalmoments_data\\\\21\\\\21_musicalmoment_3-epo.fif'\n",
    "    ],\n",
    "}\n",
    "# Use the existing `extract_features` function from your code.\n",
    "\n",
    "# This function will help us check the variance and visualize the features\n",
    "def check_variance_and_plot(features):\n",
    "    variances = np.var(features, axis=0)  # Calculate variance along the column\n",
    "    print(\"Variances of features:\", variances)\n",
    "\n",
    "    # Plot the variance\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(range(len(variances)), variances)\n",
    "    plt.title('Feature Variances')\n",
    "    plt.xlabel('Feature index')\n",
    "    plt.ylabel('Variance')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot histograms for each feature\n",
    "    num_features = features.shape[1]\n",
    "    fig, axes = plt.subplots(num_features, 1, figsize=(10, num_features*2))\n",
    "    for i in range(num_features):\n",
    "        axes[i].hist(features[:, i], bins=50)\n",
    "        axes[i].set_title(f'Feature {i} distribution')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Placeholder for all features for debugging\n",
    "all_features_debug = {}\n",
    "\n",
    "# Iterate over each subject and epoch file\n",
    "for subject, epoch_paths in processed_epochs_paths.items():\n",
    "    for epoch_path in epoch_paths:\n",
    "        # Load the epochs\n",
    "        epochs = mne.read_epochs(epoch_path, preload=True)\n",
    "\n",
    "        # Extract features\n",
    "        features = extract_features(epochs)\n",
    "\n",
    "        # Check variance and plot for the current epoch\n",
    "        check_variance_and_plot(features)\n",
    "\n",
    "        # Prepare the path string for the dictionary key\n",
    "        # Replace backslashes with forward slashes to avoid the SyntaxError in f-strings\n",
    "        path_key = epoch_path.replace('\\\\', '/')\n",
    "        \n",
    "        # Store the features for further debugging if needed\n",
    "        all_features_debug[f\"{subject}_{path_key.split('/')[-1]}\"] = features\n",
    "\n",
    "# Now you can inspect the variances and distributions to see if the features are too similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw file:\n",
    " 'C:\\Users\\josep\\Music&Topology\\all-subjects\\sub-02\\eeg\\sub-02_task-classicalMusic_eeg.edf'\n",
    "corresponding timestamps for epochs:\n",
    "17.092-175.484 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub02\\\\sub02_music-and-reporting_p3-epo.fif'\n",
    "175.484-308.868 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\sub02\\\\sub02_music-and-reporting_p6-or-p2-epo.fif'\n",
    "\n",
    "raw file:\n",
    "'C:\\Users\\josep\\Music&Topology\\all-subjects\\sub-04\\eeg\\sub-04_task-classicalMusic_eeg.edf'\n",
    "corresponding timestamps for epochs:\n",
    "175.555-337.511 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub04\\\\sub04_music-and-reporting_p5-undecided-epo.fif'\n",
    "337.511-472.401 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub04\\\\sub04_music-and-reporting_p6-or-p2-epo.fif'\n",
    "605.756-761.398 (s) for 'C:\\\\Users\\\\josep\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub04\\\\sub04_music-and-reporting_p3-epo.fif'\n",
    "1059.81-1225.402 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub04\\\\sub04_music-and-reporting_p5-undecided-epo.fif'\n",
    "\n",
    "raw file:\n",
    "'C:\\Users\\josep\\Music&Topology\\all-subjects\\sub-05\\eeg\\sub-05_task-classicalMusic_eeg.edf'\n",
    "corresponding timestamps for epochs:\n",
    "14.594-148.165 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub05\\\\sub05_music-and-reporting_p6-or-p2-epo.fif'\n",
    "282.772-448.714 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub05\\\\sub05_music-and-reporting_p5-undecided-epo.fif'\n",
    "908.811-1065.856 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub05\\\\sub05_music-and-reporting_p3-epo.fif'\n",
    "1224.351-1389.993 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub05\\\\sub05_music-and-reporting_p5-undecided-epo.fif'\n",
    "\n",
    "raw file:\n",
    "'C:\\Users\\josep\\Music&Topology\\all-subjects\\sub-10\\eeg\\sub-10_task-classicalMusic_eeg.edf'\n",
    "corresponding timestamps for epochs:\n",
    "14.906-149.429 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub10\\\\sub10_music-and-reporting_p6-or-p2-epo.fif'\n",
    "447.09-602.681 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub10\\\\sub10_music-and-reporting_p3-epo.fif'\n",
    "769.324-932.846 (s) for C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub10\\\\sub10_music-and-reporting_p5-undecided-epo.fif'\n",
    "1089.656-1254.697 (s) for C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub10\\\\sub10_music-and-reporting_p5-undecided-epo.fif'\n",
    "\n",
    "raw file:\n",
    "'C:\\Users\\josep\\Music&Topology\\all-subjects\\sub-17\\eeg\\sub-17_task-classicalMusic_eeg.edf'\n",
    "corresponding timestamps for epochs:\n",
    "14.109-172.254 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub17\\\\sub17_music-and-reporting_p3-epo.fif'\n",
    "172.254-339.316 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub17\\\\sub17_music-and-reporting_p5-undecided-epo.fif'\n",
    "628.262-791.817 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub17\\\\sub17_music-and-reporting_p5-undecided-epo.fif'\n",
    "791.817-925.556 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub17\\\\sub17_music-and-reporting_p6-or-p2-epo.fif'\n",
    "\n",
    "raw file:\n",
    "'C:\\Users\\josep\\Music&Topology\\all-subjects\\sub-19\\eeg\\sub-19_task-classicalMusic_eeg.edf'\n",
    "corresponding timestamps for epochs:\n",
    "179.071-344.363 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub19\\\\sub19_music-and-reporting_p5-undecided-epo.fif'\n",
    "502.826-637.032 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub19\\\\sub19_music-and-reporting_p6-or-p2-epo.fif'\n",
    "637.032-794.395 (s) for  'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub19\\\\sub19_music-and-reporting_p3-epo.fif'\n",
    "1124.542-1288.438 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub19\\\\sub19_music-and-reporting_p5-undecided-epo.fif'\n",
    "\n",
    "raw file:\n",
    "'C:\\Users\\josep\\Music&Topology\\all-subjects\\sub-21\\eeg\\sub-21_task-classicalMusic_eeg.edf'\n",
    "corresponding timestamps for epochs:\n",
    "180.259-345.484 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub21\\\\sub21_music-and-reporting_p5-undecided-epo.fif'\n",
    "502.01-636.067 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub21\\\\sub21_music-and-reporting_p6-or-p2-epo.fif''\n",
    "636.067-791.376 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub21\\\\sub21_music-and-reporting_p3-epo.fif'\n",
    "1121.608-1285.497 (s) for 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\\\\sub21\\\\sub21_music-and-reporting_p5-undecided-epo.fif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of music-listening trialsegs files to visualize\n",
    "epoch_files = [\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 4: trial segmentations layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "general outline:\n",
    "    1) Load the raw EEG data and events from the provided annotations or events.tsv file.\n",
    "    2) Plot the non-EEG channels (like 'music', 'trialtype', 'ft_valence', 'ft_arousal') to visually inspect them.\n",
    "    3) Based on your visual inspection, decide on the events that correspond to each trial's start and end.\n",
    "    4) Epoch the data based on these manually determined events.\n",
    "    5) Label each epoch based on the conditions you described earlier.\n",
    "    6) Save the labeled epochs.\n",
    "\n",
    "selected_subjects = ['02', '04', '05', '10', '16', '17', '19', '21']\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 4 —> getting sample numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the DL model (first time), have 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\Analysis1\\processed-for-DL\\sub-xx_task-classicalMusic_eeg_raw-with-ICA-weights-filtered-and-referenced_DL.fif' for edf_file_path\n",
    "; After running the DL model and having obtained its classifications for the music-listening data, change to 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\Analysis1\\\\processed-for-analysis\\\\sub-xx_task-classicalMusic_eeg_raw-with-ICA-weights-filtered-and-referenced_analysis.fif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "music_listening_piece1_epochs = all_epochs_sub02['label == \"music-listening_piece1\"']\n",
    "music_and_reporting_piece2_epochs = all_epochs_sub02['label == \"music-and-reporting_piece2\"']\n",
    "reporting_only_epochs = all_epochs_sub02['label == \"reporting-only_piece3\"']\n",
    "'''\n",
    "\n",
    "# subject 2's sample numbers\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-02\\\\eeg\\\\sub-02_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "\n",
    "sfreq = raw.info['sfreq']  # get the sampling frequency\n",
    "\n",
    "start_trial_1_sub02 = int(17.092 * sfreq)\n",
    "end_trial_1_sub02 = int(175.484 * sfreq)\n",
    "\n",
    "start_trial_2_sub02 = int(175.484 * sfreq)\n",
    "end_trial_2_sub02 = int(308.868 * sfreq)\n",
    "\n",
    "start_trial_3_sub02 = int(308.868 * sfreq)\n",
    "end_trial_3_sub02 = int(474.824 * sfreq)\n",
    "\n",
    "start_trial_4_sub02 = int(474.824 * sfreq)\n",
    "end_trial_4_sub02 = int(639.524 * sfreq)\n",
    "\n",
    "start_trial_5_sub02 = int(639.524 * sfreq)\n",
    "end_trial_5_sub02 = int(803.843 * sfreq)\n",
    "\n",
    "start_trial_6_sub02 = int(803.843 * sfreq)\n",
    "end_trial_6_sub02 = int(971.251 * sfreq)\n",
    "\n",
    "start_trial_7_sub02 = int(971.251 * sfreq)\n",
    "end_trial_7_sub02 = int(1129.759 * sfreq)\n",
    "\n",
    "start_trial_8_sub02 = int(1129.759 * sfreq)\n",
    "end_trial_8_sub02 = int(1294.88 * sfreq)\n",
    "\n",
    "start_trial_9_sub02 = int(1294.88 * sfreq)\n",
    "end_trial_9_sub02 = int(1451.318 * sfreq)\n",
    "\n",
    "start_trial_10_sub02 = int(1451.318 * sfreq)\n",
    "end_trial_10_sub02 = int(1585.837 * sfreq)\n",
    "\n",
    "start_trial_11_sub02 = int(1585.837 * sfreq)\n",
    "end_trial_11_sub02 = int(1750.842 * sfreq)\n",
    "\n",
    "start_trial_12_sub02 = int(1750.842 * sfreq)\n",
    "end_trial_12_sub02 = int(raw.times[-1] * sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous value for start_trial_11_sub02: 1585837\n",
    "raw.times[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject 4's sample numbers\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-04\\\\eeg\\\\sub-04_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "\n",
    "sfreq = raw.info['sfreq']  # get the sampling frequency\n",
    "\n",
    "start_trial_1_sub04 = int(17.397 * sfreq)\n",
    "end_trial_1_sub04 = int(173.555 * sfreq)\n",
    "\n",
    "start_trial_2_sub04 = int(173.555 * sfreq)\n",
    "end_trial_2_sub04 = int(337.511 * sfreq)\n",
    "\n",
    "start_trial_3_sub04 = int(337.511 * sfreq)\n",
    "end_trial_3_sub04 = int(472.401 * sfreq)\n",
    "\n",
    "start_trial_4_sub04 = int(472.401 * sfreq)\n",
    "end_trial_4_sub04 = int(605.756 * sfreq)\n",
    "\n",
    "start_trial_5_sub04 = int(605.756 * sfreq)\n",
    "end_trial_5_sub04 = int(761.398 * sfreq)\n",
    "\n",
    "start_trial_6_sub04 = int(761.398 * sfreq)\n",
    "end_trial_6_sub04 = int(895.254 * sfreq)\n",
    "\n",
    "start_trial_7_sub04 = int(895.254 * sfreq)\n",
    "end_trial_7_sub04 = int(1059.81 * sfreq)\n",
    "\n",
    "start_trial_8_sub04 = int(1059.81 * sfreq)\n",
    "end_trial_8_sub04 = int(1225.402 * sfreq)\n",
    "\n",
    "start_trial_9_sub04 = int(1225.402 * sfreq)\n",
    "end_trial_9_sub04 = int(1392.295 * sfreq)\n",
    "\n",
    "start_trial_10_sub04 = int(1392.295 * sfreq)\n",
    "end_trial_10_sub04 = int(1550.308 * sfreq)\n",
    "\n",
    "start_trial_11_sub04 = int(1550.308 * sfreq)\n",
    "end_trial_11_sub04 = int(1713.795 * sfreq)\n",
    "\n",
    "start_trial_12_sub04 = int(1713.795 * sfreq)\n",
    "end_trial_12_sub04 = int(raw.times[-1] * sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject 5's sample numbers\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-05\\\\eeg\\\\sub-05_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "\n",
    "sfreq = raw.info['sfreq']  # get the sampling frequency\n",
    "\n",
    "start_trial_1_sub05 = int(14.594 * sfreq)\n",
    "end_trial_1_sub05 = int(148.165 * sfreq)\n",
    "\n",
    "start_trial_2_sub05 = int(148.165 * sfreq)\n",
    "end_trial_2_sub05 = int(282.772 * sfreq)\n",
    "\n",
    "start_trial_3_sub05 = int(282.772 * sfreq)\n",
    "end_trial_3_sub05 = int(448.714 * sfreq)\n",
    "\n",
    "start_trial_4_sub05 = int(448.714 * sfreq)\n",
    "end_trial_4_sub05 = int(611.869 * sfreq)\n",
    "\n",
    "start_trial_5_sub05 = int(611.869 * sfreq)\n",
    "end_trial_5_sub05 = int(775.824 * sfreq)\n",
    "\n",
    "start_trial_6_sub05 = int(775.824 * sfreq)\n",
    "end_trial_6_sub05 = int(908.811 * sfreq)\n",
    "\n",
    "start_trial_7_sub05 = int(908.811 * sfreq)\n",
    "end_trial_7_sub05 = int(1065.856 * sfreq)\n",
    "\n",
    "start_trial_8_sub05 = int(1065.856 * sfreq)\n",
    "end_trial_8_sub05 = int(1224.351 * sfreq)\n",
    "\n",
    "start_trial_9_sub05 = int(1224.351 * sfreq)\n",
    "end_trial_9_sub05 = int(1389.993 * sfreq)\n",
    "\n",
    "start_trial_10_sub05 = int(1389.993 * sfreq)\n",
    "end_trial_10_sub05 = int(1555.836 * sfreq)\n",
    "\n",
    "start_trial_11_sub05 = int(1555.836 * sfreq)\n",
    "end_trial_11_sub05 = int(1722.094 * sfreq)\n",
    "\n",
    "start_trial_12_sub05 = int(1722.094 * sfreq)\n",
    "end_trial_12_sub05 = int(raw.times[-1] * sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject 10's sample numbers\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-10\\\\eeg\\\\sub-10_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "\n",
    "start_trial_1_sub10 = int(14.906 * sfreq)\n",
    "end_trial_1_sub10 = int(149.429 * sfreq)\n",
    "\n",
    "start_trial_2_sub10 = int(149.429 * sfreq)\n",
    "end_trial_2_sub10 = int(282.784 * sfreq)\n",
    "\n",
    "start_trial_3_sub10 = int(282.784 * sfreq)\n",
    "end_trial_3_sub10 = int(447.09 * sfreq)\n",
    "\n",
    "start_trial_4_sub10 = int(447.09 * sfreq)\n",
    "end_trial_4_sub10 = int(602.681 * sfreq)\n",
    "\n",
    "start_trial_5_sub10 = int(602.681 * sfreq)\n",
    "end_trial_5_sub10 = int(769.324 * sfreq)\n",
    "\n",
    "start_trial_6_sub10 = int(769.324 * sfreq)\n",
    "end_trial_6_sub10 = int(932.846 * sfreq)\n",
    "\n",
    "start_trial_7_sub10 = int(932.846 * sfreq)\n",
    "end_trial_7_sub10 = int(1089.656 * sfreq)\n",
    "\n",
    "start_trial_8_sub10 = int(1089.656 * sfreq)\n",
    "end_trial_8_sub10 = int(1254.697 * sfreq)\n",
    "\n",
    "start_trial_9_sub10 = int(1254.697 * sfreq)\n",
    "end_trial_9_sub10 = int(1410.689 * sfreq)\n",
    "\n",
    "start_trial_10_sub10 = int(1410.689 * sfreq)\n",
    "end_trial_10_sub10 = int(1543.478 * sfreq)\n",
    "\n",
    "start_trial_11_sub10 = int(1543.478 * sfreq)\n",
    "end_trial_11_sub10 = int(1709.218 * sfreq)\n",
    "\n",
    "start_trial_12_sub10 = int(1709.218 * sfreq)\n",
    "end_trial_12_sub10 = int(raw.times[-1] * sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject 16's sample numbers\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-16\\\\eeg\\\\sub-16_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "\n",
    "start_trial_1_sub16 = int(14.197 * sfreq)\n",
    "end_trial_1_sub16 = int(147.534 * sfreq)\n",
    "\n",
    "start_trial_2_sub16 = int(147.534 * sfreq)\n",
    "end_trial_2_sub16 = int(282.259 * sfreq)\n",
    "\n",
    "start_trial_3_sub16 = int(282.259 * sfreq)\n",
    "end_trial_3_sub16 = int(447.867 * sfreq)\n",
    "\n",
    "start_trial_4_sub16 = int(447.867 * sfreq)\n",
    "end_trial_4_sub16 = int(603.475 * sfreq)\n",
    "\n",
    "start_trial_5_sub16 = int(603.475 * sfreq)\n",
    "end_trial_5_sub16 = int(759.684 * sfreq)\n",
    "\n",
    "start_trial_6_sub16 = int(759.684 * sfreq)\n",
    "end_trial_6_sub16 = int(924.14 * sfreq)\n",
    "\n",
    "start_trial_7_sub16 = int(924.14 * sfreq)\n",
    "end_trial_7_sub16 = int(1091.552 * sfreq)\n",
    "\n",
    "start_trial_8_sub16 = int(1091.552 * sfreq)\n",
    "end_trial_8_sub16 = int(1256.392 * sfreq)\n",
    "\n",
    "start_trial_9_sub16 = int(1256.392 * sfreq)\n",
    "end_trial_9_sub16 = int(1413.454 * sfreq)\n",
    "\n",
    "start_trial_10_sub16 = int(1413.454 * sfreq)\n",
    "end_trial_10_sub16 = int(1578.294 * sfreq)\n",
    "\n",
    "start_trial_11_sub16 = int(1578.294 * sfreq)\n",
    "end_trial_11_sub16 = int(1711.449 * sfreq)\n",
    "\n",
    "start_trial_12_sub16 = int(1711.449 * sfreq)\n",
    "end_trial_12_sub16 = int(raw.times[-1] * sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject 17's sample numbers\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-17\\\\eeg\\\\sub-17_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "\n",
    "start_trial_1_sub17 = int(14.109 * sfreq)\n",
    "end_trial_1_sub17 = int(172.254 * sfreq)\n",
    "\n",
    "start_trial_2_sub17 = int(172.254 * sfreq)\n",
    "end_trial_2_sub17 = int(339.316 * sfreq)\n",
    "\n",
    "start_trial_3_sub17 = int(339.316 * sfreq)\n",
    "end_trial_3_sub17 = int(471.986 * sfreq)\n",
    "\n",
    "start_trial_4_sub17 = int(471.986 * sfreq)\n",
    "end_trial_4_sub17 = int(628.262 * sfreq)\n",
    "\n",
    "start_trial_5_sub17 = int(628.262 * sfreq)\n",
    "end_trial_5_sub17 = int(791.817 * sfreq)\n",
    "\n",
    "start_trial_6_sub17 = int(791.817 * sfreq)\n",
    "end_trial_6_sub17 = int(925.556 * sfreq)\n",
    "\n",
    "start_trial_7_sub17 = int(925.556 * sfreq)\n",
    "end_trial_7_sub17 = int(1091.365 * sfreq)\n",
    "\n",
    "start_trial_8_sub17 = int(1091.365 * sfreq)\n",
    "end_trial_8_sub17 = int(1247.358 * sfreq)\n",
    "\n",
    "start_trial_9_sub17 = int(1247.358 * sfreq)\n",
    "end_trial_9_sub17 = int(1412.299 * sfreq)\n",
    "\n",
    "start_trial_10_sub17 = int(1412.299 * sfreq)\n",
    "end_trial_10_sub17 = int(1577.756 * sfreq)\n",
    "\n",
    "start_trial_11_sub17 = int(1577.756 * sfreq)\n",
    "end_trial_11_sub17 = int(1711.364 * sfreq)\n",
    "\n",
    "start_trial_12_sub17 = int(1711.364 * sfreq)\n",
    "end_trial_12_sub17 = int(raw.times[-1] * sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject 19's sample numbers\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-19\\\\eeg\\\\sub-19_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "\n",
    "start_trial_1_sub19 = int(12.362 * sfreq)\n",
    "end_trial_1_sub19 = int(179.071 * sfreq)\n",
    "\n",
    "start_trial_2_sub19 = int(179.071 * sfreq)\n",
    "end_trial_2_sub19 = int(344.363 * sfreq)\n",
    "\n",
    "start_trial_3_sub19 = int(344.363 * sfreq)\n",
    "end_trial_3_sub19 = int(502.826 * sfreq)\n",
    "\n",
    "start_trial_4_sub19 = int(502.826 * sfreq)\n",
    "end_trial_4_sub19 = int(637.032 * sfreq)\n",
    "\n",
    "start_trial_5_sub19 = int(637.032 * sfreq)\n",
    "end_trial_5_sub19 = int(794.395 * sfreq)\n",
    "\n",
    "start_trial_6_sub19 = int(794.395 * sfreq)\n",
    "end_trial_6_sub19 = int(959.235 * sfreq)\n",
    "\n",
    "start_trial_7_sub19 = int(959.235 * sfreq)\n",
    "end_trial_7_sub19 = int(1124.542 * sfreq)\n",
    "\n",
    "start_trial_8_sub19 = int(1124.542 * sfreq)\n",
    "end_trial_8_sub19 = int(1288.348 * sfreq)\n",
    "\n",
    "start_trial_9_sub19 = int(1288.348 * sfreq)\n",
    "end_trial_9_sub19 = int(1422.805 * sfreq)\n",
    "\n",
    "start_trial_10_sub19 = int(1422.805 * sfreq)\n",
    "end_trial_10_sub19 = int(1557.011 * sfreq)\n",
    "\n",
    "start_trial_11_sub19 = int(1557.011 * sfreq)\n",
    "end_trial_11_sub19 = int(1713.354 * sfreq)\n",
    "\n",
    "start_trial_12_sub19 = int(1713.354 * sfreq)\n",
    "end_trial_12_sub19 = int(raw.times[-1] * sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject 21's sample numbers\n",
    "\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-21\\\\eeg\\\\sub-21_task-classicalMusic_eeg.edf'  \n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "\n",
    "start_trial_1_sub21 = int(13.466 * sfreq)\n",
    "end_trial_1_sub21 = int(180.259 * sfreq)\n",
    "\n",
    "start_trial_2_sub21 = int(180.259 * sfreq)\n",
    "end_trial_2_sub21 = int(345.484 * sfreq)\n",
    "\n",
    "start_trial_3_sub21 = int(345.484 * sfreq)\n",
    "end_trial_3_sub21 = int(502.01 * sfreq)\n",
    "\n",
    "start_trial_4_sub21 = int(502.01 * sfreq)\n",
    "end_trial_4_sub21 = int(636.067 * sfreq)\n",
    "\n",
    "start_trial_5_sub21 = int(636.067 * sfreq)\n",
    "end_trial_5_sub21 = int(791.376 * sfreq)\n",
    "\n",
    "start_trial_6_sub21 = int(791.376 * sfreq)\n",
    "end_trial_6_sub21 = int(956.333 * sfreq)\n",
    "\n",
    "start_trial_7_sub21 = int(956.333 * sfreq)\n",
    "end_trial_7_sub21 = int(1121.608 * sfreq)\n",
    "\n",
    "start_trial_8_sub21 = int(1121.608 * sfreq)\n",
    "end_trial_8_sub21 = int(1285.497 * sfreq)\n",
    "\n",
    "start_trial_9_sub21 = int(1285.497 * sfreq)\n",
    "end_trial_9_sub21 = int(1417.766 * sfreq)\n",
    "\n",
    "start_trial_10_sub21 = int(1417.766 * sfreq)\n",
    "end_trial_10_sub21 = int(1550.101 * sfreq)\n",
    "\n",
    "start_trial_11_sub21 = int(1550.101 * sfreq)\n",
    "end_trial_11_sub21 = int(1708.518 * sfreq)\n",
    "\n",
    "start_trial_12_sub21 = int(1708.518 * sfreq)\n",
    "end_trial_12_sub21 = int(raw.times[-1] * sfreq)\n",
    "'''\n",
    "11/4 update: it's fine for DL, I'm not using the whole trial anyways; \n",
    "for steps 1-2, proceed as is as I can look at where the music cuts off, if it does, when I visualize trial-by-trial;\n",
    "for step 3, just look at where the music cuts off and use that estimated timepoint to get the new piece name, no need for 亂七八糟與以下的\n",
    "\n",
    "----\n",
    "\n",
    "Also, to clarify a concern I had from the above, when we said the following:\n",
    "\n",
    "'To add the end_trial_12_sub02 event based on the final timepoint of the music channel, you can access the last timepoint of a channel by looking at the raw data's times attribute. Since you're interested in the final timepoint of the music channel, you'd find the last entry in the raw.times array and then multiply by the sampling frequency to get the sample number.\n",
    "Here's the adjusted code for subject 02, taking into account the extraction of end_trial_12_sub02:\n",
    "# extracting sample numbers\n",
    "\n",
    "sfreq = raw.info['sfreq'] \n",
    "...\n",
    "start_trial_11_sub02 = int(1585.837 * sfreq)\n",
    "end_trial_11_sub02 = int(1750.842 * sfreq)\n",
    "\n",
    "start_trial_12_sub02 = int(1750.842 * sfreq)\n",
    "end_trial_12_sub02 = int(raw.times[-1] * sfreq)  # Last timepoint of the music channel converted to sample number\n",
    "\n",
    "# labeling trialsegs\n",
    "\n",
    "events_sub02 = [\n",
    "    # ... [previous events here]\n",
    "    [start_trial_12_sub02, 0, 1],\n",
    "    [end_trial_12_sub02, 0, 2]\n",
    "]\n",
    "\n",
    "# Rest of the code remains unchanged\n",
    "\n",
    "I am unsure that the code we had will actually get the last timepoint of the music channel I meant, the non-EEG music data channel, within the raw '...classical_music_eeg.edf' file. We previously had code that might be re-adaptable to get the last timepoint of the non-EEG channel of each subject; perhaps just make non_eeg_channels = ['music'] and get the last timepoint right under? \n",
    "\n",
    "for dir in selected_subject_dirs:\n",
    "    # Get only the classical music EDF files\n",
    "    classical_music_files = list(dir.glob('eeg/*task-classicalMusic_eeg.edf'))\n",
    "    \n",
    "    for edf_file in classical_music_files:\n",
    "        # Load the data\n",
    "        raw = mne.io.read_raw_edf(edf_file, preload=True)\n",
    "        \n",
    "        # Get the indices of the non-EEG channels\n",
    "        non_eeg_channels = ['ft_valance', 'ft_arousal', 'music', 'trialtype']\n",
    "\n",
    "Then perhaps, I can just select from a list of these last timepoints for each subject's _end_trial_12; example from subject 21 to change:\n",
    "\n",
    "# edit this...\n",
    "\n",
    "...\n",
    "start_trial_12_sub21 = int(1708.518 * sfreq)\n",
    "end_trial_12_sub21 = int(raw.times[-1] * sfreq)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 4 —> subject-by-subject cells for trialsegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Subject 2!\n",
    "'''\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\raw-with-ICA-weights\\\\raw-with-ICA-weights\\\\sub-02_task-classicalMusic_eeg_raw-with-ICA-weights.fif' \n",
    "raw = mne.io.read_raw_fif(edf_file_path, preload=True)\n",
    "\n",
    "# Define events manually based on step 2\n",
    "# Here's a hypothetical example:\n",
    "events_sub02 = [\n",
    "    [start_trial_1_sub02, 0, 1],\n",
    "    [end_trial_1_sub02, 0, 2],\n",
    "    [start_trial_2_sub02, 0, 1],\n",
    "    [end_trial_2_sub02, 0, 2],\n",
    "    [start_trial_3_sub02, 0, 1],\n",
    "    [end_trial_3_sub02, 0, 2],\n",
    "    [start_trial_4_sub02, 0, 1],\n",
    "    [end_trial_4_sub02, 0, 2],\n",
    "    [start_trial_5_sub02, 0, 1],\n",
    "    [end_trial_5_sub02, 0, 2],\n",
    "    [start_trial_6_sub02, 0, 1],\n",
    "    [end_trial_6_sub02, 0, 2],\n",
    "    [start_trial_7_sub02, 0, 1],\n",
    "    [end_trial_7_sub02, 0, 2],\n",
    "    [start_trial_8_sub02, 0, 1],\n",
    "    [end_trial_8_sub02, 0, 2],\n",
    "    [start_trial_9_sub02, 0, 1],\n",
    "    [end_trial_9_sub02, 0, 2],\n",
    "    [start_trial_10_sub02, 0, 1],\n",
    "    [end_trial_10_sub02, 0, 2],\n",
    "    [start_trial_11_sub02, 0, 1],\n",
    "    [end_trial_11_sub02, 0, 2],\n",
    "    [start_trial_12_sub02, 0, 1],\n",
    "    [end_trial_12_sub02, 0, 2]\n",
    "]\n",
    "\n",
    "# Create trial segmentations (trialsegs) based on these events\n",
    "trial_starts_sub02 = [event[0] for event in events_sub02 if event[2] == 1]\n",
    "trial_ends_sub02 = [event[0] for event in events_sub02 if event[2] == 2]\n",
    "\n",
    "tmax_values_sub02 = [(end - start) / raw.info['sfreq'] for start, end in zip(trial_starts_sub02, trial_ends_sub02)]\n",
    "\n",
    "trialsegs_sub02 = []\n",
    "for i, start in enumerate(trial_starts_sub02):\n",
    "    epochs_temp_sub02 = mne.Epochs(raw, events=[events_sub02[i*2]], event_id={'start': 1}, tmin=0, tmax=tmax_values_sub02[i], baseline=None, preload=True)\n",
    "    trialsegs_sub02.append(epochs_temp_sub02)\n",
    "\n",
    "# Manually label each trialseg\n",
    "labels_sub02 = []\n",
    "for ts in trialsegs_sub02:\n",
    "    label = input(f\"Enter label for trialseg {len(labels_sub02)+1}: \")  # This will prompt you to enter a label for each trialseg\n",
    "    labels_sub02.append(label)\n",
    "\n",
    "# Assign metadata to each individual mne.Epochs object\n",
    "for i, ts in enumerate(trialsegs_sub02):\n",
    "    ts.metadata = pd.DataFrame({'label': [labels_sub02[i]]})\n",
    "\n",
    "# Create a folder for the subject's trialsegs if it doesn't exist\n",
    "subject_id = \"sub02\"\n",
    "trialsegs_output_folder = os.path.join(\"C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\", subject_id)\n",
    "if not os.path.exists(trialsegs_output_folder):\n",
    "    os.makedirs(trialsegs_output_folder)\n",
    "\n",
    "# Save each labeled trialseg using its label as the name\n",
    "for ts, label in zip(trialsegs_sub02, labels_sub02):\n",
    "    safe_label = label.replace(\" \", \"_\")  # to ensure filename compatibility\n",
    "    ts.save(os.path.join(trialsegs_output_folder, f\"{subject_id}_{safe_label}-epo.fif\"), overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Subject 4!\n",
    "reporting-only\n",
    "\n",
    "'''\n",
    "# Load your data\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\raw-with-ICA-weights\\\\raw-with-ICA-weights\\\\sub-04_task-classicalMusic_eeg_raw-with-ICA-weights.fif' \n",
    "raw = mne.io.read_raw_fif(edf_file_path, preload=True)\n",
    "\n",
    "# Define events manually based on step 2\n",
    "# Here's a hypothetical example:\n",
    "events_sub04 = [\n",
    "    [start_trial_1_sub04, 0, 1],\n",
    "    [end_trial_1_sub04, 0, 2],\n",
    "    [start_trial_2_sub04, 0, 1],\n",
    "    [end_trial_2_sub04, 0, 2],\n",
    "    [start_trial_3_sub04, 0, 1],\n",
    "    [end_trial_3_sub04, 0, 2],\n",
    "    [start_trial_4_sub04, 0, 1],\n",
    "    [end_trial_4_sub04, 0, 2],\n",
    "    [start_trial_5_sub04, 0, 1],\n",
    "    [end_trial_5_sub04, 0, 2],\n",
    "    [start_trial_6_sub04, 0, 1],\n",
    "    [end_trial_6_sub04, 0, 2],\n",
    "    [start_trial_7_sub04, 0, 1],\n",
    "    [end_trial_7_sub04, 0, 2],\n",
    "    [start_trial_8_sub04, 0, 1],\n",
    "    [end_trial_8_sub04, 0, 2],\n",
    "    [start_trial_9_sub04, 0, 1],\n",
    "    [end_trial_9_sub04, 0, 2],\n",
    "    [start_trial_10_sub04, 0, 1],\n",
    "    [end_trial_10_sub04, 0, 2],\n",
    "    [start_trial_11_sub04, 0, 1],\n",
    "    [end_trial_11_sub04, 0, 2],\n",
    "    [start_trial_12_sub04, 0, 1],\n",
    "    [end_trial_12_sub04, 0, 2]\n",
    "]\n",
    "\n",
    "# Create trial segmentations (trialsegs) based on these events\n",
    "trial_starts_sub04 = [event[0] for event in events_sub04 if event[2] == 1]\n",
    "trial_ends_sub04 = [event[0] for event in events_sub04 if event[2] == 2]\n",
    "\n",
    "tmax_values_sub04 = [(end - start) / raw.info['sfreq'] for start, end in zip(trial_starts_sub04, trial_ends_sub04)]\n",
    "\n",
    "trialsegs_sub04 = []\n",
    "for i, start in enumerate(trial_starts_sub04):\n",
    "    epochs_temp_sub04 = mne.Epochs(raw, events=[events_sub04[i*2]], event_id={'start': 1}, tmin=0, tmax=tmax_values_sub04[i], baseline=None, preload=True)\n",
    "    trialsegs_sub04.append(epochs_temp_sub04)\n",
    "\n",
    "# Manually label each trialseg\n",
    "labels_sub04 = []\n",
    "for ts in trialsegs_sub04:\n",
    "    label = input(f\"Enter label for trialseg {len(labels_sub04)+1}: \")  # This will prompt you to enter a label for each trialseg\n",
    "    labels_sub04.append(label)\n",
    "\n",
    "# Assign metadata to each individual mne.Epochs object\n",
    "for i, ts in enumerate(trialsegs_sub04):\n",
    "    ts.metadata = pd.DataFrame({'label': [labels_sub04[i]]})\n",
    "\n",
    "# Create a folder for the subject's trialsegs if it doesn't exist\n",
    "subject_id = \"sub04\"\n",
    "trialsegs_output_folder = os.path.join(\"C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\", subject_id)\n",
    "if not os.path.exists(trialsegs_output_folder):\n",
    "    os.makedirs(trialsegs_output_folder)\n",
    "\n",
    "# Save each labeled trialseg using its label as the name\n",
    "for ts, label in zip(trialsegs_sub04, labels_sub04):\n",
    "    safe_label = label.replace(\" \", \"_\")  # to ensure filename compatibility\n",
    "    ts.save(os.path.join(trialsegs_output_folder, f\"{subject_id}_{safe_label}-epo.fif\"), overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Subject 5!\n",
    "'''\n",
    "\n",
    "# Load your data\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\raw-with-ICA-weights\\\\raw-with-ICA-weights\\\\sub-05_task-classicalMusic_eeg_raw-with-ICA-weights.fif' \n",
    "raw = mne.io.read_raw_fif(edf_file_path, preload=True)\n",
    "\n",
    "# Define events manually based on step 2\n",
    "# Here's a hypothetical example:\n",
    "events_sub05 = [\n",
    "    [start_trial_1_sub05, 0, 1],\n",
    "    [end_trial_1_sub05, 0, 2],\n",
    "    [start_trial_2_sub05, 0, 1],\n",
    "    [end_trial_2_sub05, 0, 2],\n",
    "    [start_trial_3_sub05, 0, 1],\n",
    "    [end_trial_3_sub05, 0, 2],\n",
    "    [start_trial_4_sub05, 0, 1],\n",
    "    [end_trial_4_sub05, 0, 2],\n",
    "    [start_trial_5_sub05, 0, 1],\n",
    "    [end_trial_5_sub05, 0, 2],\n",
    "    [start_trial_6_sub05, 0, 1],\n",
    "    [end_trial_6_sub05, 0, 2],\n",
    "    [start_trial_7_sub05, 0, 1],\n",
    "    [end_trial_7_sub05, 0, 2],\n",
    "    [start_trial_8_sub05, 0, 1],\n",
    "    [end_trial_8_sub05, 0, 2],\n",
    "    [start_trial_9_sub05, 0, 1],\n",
    "    [end_trial_9_sub05, 0, 2],\n",
    "    [start_trial_10_sub05, 0, 1],\n",
    "    [end_trial_10_sub05, 0, 2],\n",
    "    [start_trial_11_sub05, 0, 1],\n",
    "    [end_trial_11_sub05, 0, 2],\n",
    "    [start_trial_12_sub05, 0, 1],\n",
    "    [end_trial_12_sub05, 0, 2]\n",
    "]\n",
    "\n",
    "\n",
    "# Create trial segmentations (trialsegs) based on these events\n",
    "trial_starts_sub05 = [event[0] for event in events_sub05 if event[2] == 1]\n",
    "trial_ends_sub05 = [event[0] for event in events_sub05 if event[2] == 2]\n",
    "\n",
    "tmax_values_sub05 = [(end - start) / raw.info['sfreq'] for start, end in zip(trial_starts_sub05, trial_ends_sub05)]\n",
    "\n",
    "trialsegs_sub05 = []\n",
    "for i, start in enumerate(trial_starts_sub05):\n",
    "    epochs_temp_sub05 = mne.Epochs(raw, events=[events_sub05[i*2]], event_id={'start': 1}, tmin=0, tmax=tmax_values_sub05[i], baseline=None, preload=True)\n",
    "    trialsegs_sub05.append(epochs_temp_sub05)\n",
    "\n",
    "# Manually label each trialseg\n",
    "labels_sub05 = []\n",
    "for ts in trialsegs_sub05:\n",
    "    label = input(f\"Enter label for trialseg {len(labels_sub05)+1}: \")  # This will prompt you to enter a label for each trialseg\n",
    "    labels_sub05.append(label)\n",
    "\n",
    "# Assign metadata to each individual mne.Epochs object\n",
    "for i, ts in enumerate(trialsegs_sub05):\n",
    "    ts.metadata = pd.DataFrame({'label': [labels_sub05[i]]})\n",
    "\n",
    "# Create a folder for the subject's trialsegs if it doesn't exist\n",
    "subject_id = \"sub05\"\n",
    "trialsegs_output_folder = os.path.join(\"C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\", subject_id)\n",
    "if not os.path.exists(trialsegs_output_folder):\n",
    "    os.makedirs(trialsegs_output_folder)\n",
    "\n",
    "# Save each labeled trialseg using its label as the name\n",
    "for ts, label in zip(trialsegs_sub05, labels_sub05):\n",
    "    safe_label = label.replace(\" \", \"_\")  # to ensure filename compatibility\n",
    "    ts.save(os.path.join(trialsegs_output_folder, f\"{subject_id}_{safe_label}-epo.fif\"), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Subject 10!\n",
    "'''\n",
    "\n",
    "# Load your data\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\raw-with-ICA-weights\\\\raw-with-ICA-weights\\\\sub-10_task-classicalMusic_eeg_raw-with-ICA-weights.fif' \n",
    "raw = mne.io.read_raw_fif(edf_file_path, preload=True)\n",
    "\n",
    "# Define events manually based on step 2\n",
    "events_sub10 = [\n",
    "    [start_trial_1_sub10, 0, 1],\n",
    "    [end_trial_1_sub10, 0, 2],\n",
    "    [start_trial_2_sub10, 0, 1],\n",
    "    [end_trial_2_sub10, 0, 2],\n",
    "    [start_trial_3_sub10, 0, 1],\n",
    "    [end_trial_3_sub10, 0, 2],\n",
    "    [start_trial_4_sub10, 0, 1],\n",
    "    [end_trial_4_sub10, 0, 2],\n",
    "    [start_trial_5_sub10, 0, 1],\n",
    "    [end_trial_5_sub10, 0, 2],\n",
    "    [start_trial_6_sub10, 0, 1],\n",
    "    [end_trial_6_sub10, 0, 2],\n",
    "    [start_trial_7_sub10, 0, 1],\n",
    "    [end_trial_7_sub10, 0, 2],\n",
    "    [start_trial_8_sub10, 0, 1],\n",
    "    [end_trial_8_sub10, 0, 2],\n",
    "    [start_trial_9_sub10, 0, 1],\n",
    "    [end_trial_9_sub10, 0, 2],\n",
    "    [start_trial_10_sub10, 0, 1],\n",
    "    [end_trial_10_sub10, 0, 2],\n",
    "    [start_trial_11_sub10, 0, 1],\n",
    "    [end_trial_11_sub10, 0, 2],\n",
    "    [start_trial_12_sub10, 0, 1],\n",
    "    [end_trial_12_sub10, 0, 2]\n",
    "]\n",
    "\n",
    "# Create trial segmentations (trialsegs) based on these events\n",
    "trial_starts_sub10 = [event[0] for event in events_sub10 if event[2] == 1]\n",
    "trial_ends_sub10 = [event[0] for event in events_sub10 if event[2] == 2]\n",
    "\n",
    "tmax_values_sub10 = [(end - start) / raw.info['sfreq'] for start, end in zip(trial_starts_sub10, trial_ends_sub10)]\n",
    "\n",
    "trialsegs_sub10 = []\n",
    "for i, start in enumerate(trial_starts_sub10):\n",
    "    epochs_temp_sub10 = mne.Epochs(raw, events=[events_sub10[i*2]], event_id={'start': 1}, tmin=0, tmax=tmax_values_sub10[i], baseline=None, preload=True)\n",
    "    trialsegs_sub10.append(epochs_temp_sub10)\n",
    "\n",
    "# Manually label each trialseg\n",
    "labels_sub10 = []\n",
    "for ts in trialsegs_sub10:\n",
    "    label = input(f\"Enter label for trialseg {len(labels_sub10)+1}: \")  # This will prompt you to enter a label for each trialseg\n",
    "    labels_sub10.append(label)\n",
    "\n",
    "# Assign metadata to each individual mne.Epochs object\n",
    "for i, ts in enumerate(trialsegs_sub10):\n",
    "    ts.metadata = pd.DataFrame({'label': [labels_sub10[i]]})\n",
    "\n",
    "# Create a folder for the subject's trialsegs if it doesn't exist\n",
    "subject_id = \"sub10\"\n",
    "trialsegs_output_folder = os.path.join(\"C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\", subject_id)\n",
    "if not os.path.exists(trialsegs_output_folder):\n",
    "    os.makedirs(trialsegs_output_folder)\n",
    "\n",
    "# Save each labeled trialseg using its label as the name\n",
    "for ts, label in zip(trialsegs_sub10, labels_sub10):\n",
    "    safe_label = label.replace(\" \", \"_\")  # to ensure filename compatibility\n",
    "    ts.save(os.path.join(trialsegs_output_folder, f\"{subject_id}_{safe_label}-epo.fif\"), overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Subject 17!\n",
    "'''\n",
    "\n",
    "# Load your data\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\raw-with-ICA-weights\\\\raw-with-ICA-weights\\\\sub-17_task-classicalMusic_eeg_raw-with-ICA-weights.fif' \n",
    "raw = mne.io.read_raw_fif(edf_file_path, preload=True)\n",
    "\n",
    "# Define events manually based on step 2\n",
    "# Here's a hypothetical example:\n",
    "events_sub17 = [\n",
    "    [start_trial_1_sub17, 0, 1],\n",
    "    [end_trial_1_sub17, 0, 2],\n",
    "    [start_trial_2_sub17, 0, 1],\n",
    "    [end_trial_2_sub17, 0, 2],\n",
    "    [start_trial_3_sub17, 0, 1],\n",
    "    [end_trial_3_sub17, 0, 2],\n",
    "    [start_trial_4_sub17, 0, 1],\n",
    "    [end_trial_4_sub17, 0, 2],\n",
    "    [start_trial_5_sub17, 0, 1],\n",
    "    [end_trial_5_sub17, 0, 2],\n",
    "    [start_trial_6_sub17, 0, 1],\n",
    "    [end_trial_6_sub17, 0, 2],\n",
    "    [start_trial_7_sub17, 0, 1],\n",
    "    [end_trial_7_sub17, 0, 2],\n",
    "    [start_trial_8_sub17, 0, 1],\n",
    "    [end_trial_8_sub17, 0, 2],\n",
    "    [start_trial_9_sub17, 0, 1],\n",
    "    [end_trial_9_sub17, 0, 2],\n",
    "    [start_trial_10_sub17, 0, 1],\n",
    "    [end_trial_10_sub17, 0, 2],\n",
    "    [start_trial_11_sub17, 0, 1],\n",
    "    [end_trial_11_sub17, 0, 2],\n",
    "    [start_trial_12_sub17, 0, 1],\n",
    "    [end_trial_12_sub17, 0, 2]\n",
    "]\n",
    "\n",
    "# Create trial segmentations (trialsegs) based on these events\n",
    "trial_starts_sub17 = [event[0] for event in events_sub17 if event[2] == 1]\n",
    "trial_ends_sub17 = [event[0] for event in events_sub17 if event[2] == 2]\n",
    "\n",
    "tmax_values_sub17 = [(end - start) / raw.info['sfreq'] for start, end in zip(trial_starts_sub17, trial_ends_sub17)]\n",
    "\n",
    "trialsegs_sub17 = []\n",
    "for i, start in enumerate(trial_starts_sub17):\n",
    "    epochs_temp_sub17 = mne.Epochs(raw, events=[events_sub17[i*2]], event_id={'start': 1}, tmin=0, tmax=tmax_values_sub17[i], baseline=None, preload=True)\n",
    "    trialsegs_sub17.append(epochs_temp_sub17)\n",
    "\n",
    "# Manually label each trialseg\n",
    "labels_sub17 = []\n",
    "for ts in trialsegs_sub17:\n",
    "    label = input(f\"Enter label for trialseg {len(labels_sub17)+1}: \")  # This will prompt you to enter a label for each trialseg\n",
    "    labels_sub17.append(label)\n",
    "\n",
    "# Assign metadata to each individual mne.Epochs object\n",
    "for i, ts in enumerate(trialsegs_sub17):\n",
    "    ts.metadata = pd.DataFrame({'label': [labels_sub17[i]]})\n",
    "\n",
    "# Create a folder for the subject's trialsegs if it doesn't exist\n",
    "subject_id = \"sub17\"\n",
    "trialsegs_output_folder = os.path.join(\"C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\", subject_id)\n",
    "if not os.path.exists(trialsegs_output_folder):\n",
    "    os.makedirs(trialsegs_output_folder)\n",
    "\n",
    "# Save each labeled trialseg using its label as the name\n",
    "for ts, label in zip(trialsegs_sub17, labels_sub17):\n",
    "    safe_label = label.replace(\" \", \"_\")  # to ensure filename compatibility\n",
    "    ts.save(os.path.join(trialsegs_output_folder, f\"{subject_id}_{safe_label}-epo.fif\"), overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Subject 19!\n",
    "'''\n",
    "\n",
    "# Load your data\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\raw-with-ICA-weights\\\\raw-with-ICA-weights\\\\sub-19_task-classicalMusic_eeg_raw-with-ICA-weights.fif' \n",
    "raw = mne.io.read_raw_fif(edf_file_path, preload=True)\n",
    "\n",
    "# Define events manually based on step 2\n",
    "# Here's a hypothetical example:\n",
    "events_sub19 = [\n",
    "    [start_trial_1_sub19, 0, 1],\n",
    "    [end_trial_1_sub19, 0, 2],\n",
    "    [start_trial_2_sub19, 0, 1],\n",
    "    [end_trial_2_sub19, 0, 2],\n",
    "    [start_trial_3_sub19, 0, 1],\n",
    "    [end_trial_3_sub19, 0, 2],\n",
    "    [start_trial_4_sub19, 0, 1],\n",
    "    [end_trial_4_sub19, 0, 2],\n",
    "    [start_trial_5_sub19, 0, 1],\n",
    "    [end_trial_5_sub19, 0, 2],\n",
    "    [start_trial_6_sub19, 0, 1],\n",
    "    [end_trial_6_sub19, 0, 2],\n",
    "    [start_trial_7_sub19, 0, 1],\n",
    "    [end_trial_7_sub19, 0, 2],\n",
    "    [start_trial_8_sub19, 0, 1],\n",
    "    [end_trial_8_sub19, 0, 2],\n",
    "    [start_trial_9_sub19, 0, 1],\n",
    "    [end_trial_9_sub19, 0, 2],\n",
    "    [start_trial_10_sub19, 0, 1],\n",
    "    [end_trial_10_sub19, 0, 2],\n",
    "    [start_trial_11_sub19, 0, 1],\n",
    "    [end_trial_11_sub19, 0, 2],\n",
    "    [start_trial_12_sub19, 0, 1],\n",
    "    [end_trial_12_sub19, 0, 2]\n",
    "]\n",
    "\n",
    "# Create trial segmentations (trialsegs) based on these events\n",
    "trial_starts_sub19 = [event[0] for event in events_sub19 if event[2] == 1]\n",
    "trial_ends_sub19 = [event[0] for event in events_sub19 if event[2] == 2]\n",
    "\n",
    "tmax_values_sub19 = [(end - start) / raw.info['sfreq'] for start, end in zip(trial_starts_sub19, trial_ends_sub19)]\n",
    "\n",
    "trialsegs_sub19 = []\n",
    "for i, start in enumerate(trial_starts_sub19):\n",
    "    epochs_temp_sub19 = mne.Epochs(raw, events=[events_sub19[i*2]], event_id={'start': 1}, tmin=0, tmax=tmax_values_sub19[i], baseline=None, preload=True)\n",
    "    trialsegs_sub19.append(epochs_temp_sub19)\n",
    "\n",
    "# Manually label each trialseg\n",
    "labels_sub19 = []\n",
    "for ts in trialsegs_sub19:\n",
    "    label = input(f\"Enter label for trialseg {len(labels_sub19)+1}: \")  # This will prompt you to enter a label for each trialseg\n",
    "    labels_sub19.append(label)\n",
    "\n",
    "# Assign metadata to each individual mne.Epochs object\n",
    "for i, ts in enumerate(trialsegs_sub19):\n",
    "    ts.metadata = pd.DataFrame({'label': [labels_sub19[i]]})\n",
    "\n",
    "# Create a folder for the subject's trialsegs if it doesn't exist\n",
    "subject_id = \"sub19\"\n",
    "trialsegs_output_folder = os.path.join(\"C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\", subject_id)\n",
    "if not os.path.exists(trialsegs_output_folder):\n",
    "    os.makedirs(trialsegs_output_folder)\n",
    "\n",
    "# Save each labeled trialseg using its label as the name\n",
    "for ts, label in zip(trialsegs_sub19, labels_sub19):\n",
    "    safe_label = label.replace(\" \", \"_\")  # to ensure filename compatibility\n",
    "    ts.save(os.path.join(trialsegs_output_folder, f\"{subject_id}_{safe_label}-epo.fif\"), overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Subject 21!\n",
    "'''\n",
    "\n",
    "# Load your data\n",
    "edf_file_path = 'C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\raw-with-ICA-weights\\\\raw-with-ICA-weights\\\\sub-21_task-classicalMusic_eeg_raw-with-ICA-weights.fif' \n",
    "raw = mne.io.read_raw_fif(edf_file_path, preload=True)\n",
    "\n",
    "# Define events manually based on step 2\n",
    "# Here's a hypothetical example:\n",
    "events_sub21 = [\n",
    "    [start_trial_1_sub21, 0, 1],\n",
    "    [end_trial_1_sub21, 0, 2],\n",
    "    [start_trial_2_sub21, 0, 1],\n",
    "    [end_trial_2_sub21, 0, 2],\n",
    "    [start_trial_3_sub21, 0, 1],\n",
    "    [end_trial_3_sub21, 0, 2],\n",
    "    [start_trial_4_sub21, 0, 1],\n",
    "    [end_trial_4_sub21, 0, 2],\n",
    "    [start_trial_5_sub21, 0, 1],\n",
    "    [end_trial_5_sub21, 0, 2],\n",
    "    [start_trial_6_sub21, 0, 1],\n",
    "    [end_trial_6_sub21, 0, 2],\n",
    "    [start_trial_7_sub21, 0, 1],\n",
    "    [end_trial_7_sub21, 0, 2],\n",
    "    [start_trial_8_sub21, 0, 1],\n",
    "    [end_trial_8_sub21, 0, 2],\n",
    "    [start_trial_9_sub21, 0, 1],\n",
    "    [end_trial_9_sub21, 0, 2],\n",
    "    [start_trial_10_sub21, 0, 1],\n",
    "    [end_trial_10_sub21, 0, 2],\n",
    "    [start_trial_11_sub21, 0, 1],\n",
    "    [end_trial_11_sub21, 0, 2],\n",
    "    [start_trial_12_sub21, 0, 1],\n",
    "    [end_trial_12_sub21, 0, 2]\n",
    "]\n",
    "\n",
    "# Create trial segmentations (trialsegs) based on these events\n",
    "trial_starts_sub21 = [event[0] for event in events_sub21 if event[2] == 1]\n",
    "trial_ends_sub21 = [event[0] for event in events_sub21 if event[2] == 2]\n",
    "\n",
    "tmax_values_sub21 = [(end - start) / raw.info['sfreq'] for start, end in zip(trial_starts_sub21, trial_ends_sub21)]\n",
    "\n",
    "trialsegs_sub21 = []\n",
    "for i, start in enumerate(trial_starts_sub21):\n",
    "    epochs_temp_sub21 = mne.Epochs(raw, events=[events_sub21[i*2]], event_id={'start': 1}, tmin=0, tmax=tmax_values_sub21[i], baseline=None, preload=True)\n",
    "    trialsegs_sub21.append(epochs_temp_sub21)\n",
    "\n",
    "# Manually label each trialseg\n",
    "labels_sub21 = []\n",
    "for ts in trialsegs_sub21:\n",
    "    label = input(f\"Enter label for trialseg {len(labels_sub21)+1}: \")  # This will prompt you to enter a label for each trialseg\n",
    "    labels_sub21.append(label)\n",
    "\n",
    "# Assign metadata to each individual mne.Epochs object\n",
    "for i, ts in enumerate(trialsegs_sub21):\n",
    "    ts.metadata = pd.DataFrame({'label': [labels_sub21[i]]})\n",
    "\n",
    "# Create a folder for the subject's trialsegs if it doesn't exist\n",
    "subject_id = \"sub21\"\n",
    "trialsegs_output_folder = os.path.join(\"C:\\\\Users\\\\josep\\\\Music&Topology\\\\all work ;)\\\\Analysis1\\\\trialsegs_data\", subject_id)\n",
    "if not os.path.exists(trialsegs_output_folder):\n",
    "    os.makedirs(trialsegs_output_folder)\n",
    "\n",
    "# Save each labeled trialseg using its label as the name\n",
    "for ts, label in zip(trialsegs_sub21, labels_sub21):\n",
    "    safe_label = label.replace(\" \", \"_\")  # to ensure filename compatibility\n",
    "    ts.save(os.path.join(trialsegs_output_folder, f\"{subject_id}_{safe_label}-epo.fif\"), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define epochs for each subject based on the above visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Continuing manually, patient-by-patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique parent/subject directories from all_edf_files\n",
    "subject_dirs_with_edf = list({file.parent for file in all_edf_files})\n",
    "\n",
    "# Filter out directories that don't match the 'sub-XX' format\n",
    "subject_dirs_with_edf = [dir for dir in subject_dirs_with_edf if 'sub-' in dir.name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- below: older analyses, but leaving code for possible re-purposing later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_edf('C:\\\\Users\\\\josep\\\\Music&Topology\\\\all-subjects\\\\sub-01\\\\eeg\\\\sub-01_task-classicalMusic_eeg.edf', preload=True)\n",
    "\n",
    "# Define frequency bands\n",
    "theta_band = (4, 7)\n",
    "alpha_band = (8, 13)\n",
    "\n",
    "# Bandpass filter the data for theta frequency band\n",
    "raw_theta = raw.copy().filter(l_freq=theta_band[0], h_freq=theta_band[1])\n",
    "\n",
    "# Bandpass filter the data for alpha frequency band\n",
    "raw_alpha = raw.copy().filter(l_freq=alpha_band[0], h_freq=alpha_band[1])\n",
    "\n",
    "# Visualize a representative channel for both filtered data\n",
    "start, stop = raw.time_as_index([0, 1700])  # 6 seconds of data from time 194 to 200\n",
    "times = raw.times[start:stop]\n",
    "\n",
    "# Extracting data for channel 'Fp1'\n",
    "theta_data, _ = raw_theta['Fp1', start:stop]\n",
    "alpha_data, _ = raw_alpha['Fp1', start:stop]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Theta band\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(times, theta_data.T)\n",
    "plt.title('Theta Filtered EEG Data for Channel Fp1 (194s to 200s)')\n",
    "plt.ylabel('EEG amplitude (uV)')\n",
    "\n",
    "# Alpha band\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(times, alpha_data.T)\n",
    "plt.title('Alpha Filtered EEG Data for Channel Fp1 (194s to 200s)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('EEG amplitude (uV)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
